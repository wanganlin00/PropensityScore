[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PropensityScore",
    "section": "",
    "text": "推荐阅读\n\nPropensity score matching with R: conventional methods and new features\nApplied Propensity Score Analysis with R",
    "crumbs": [
      "推荐阅读"
    ]
  },
  {
    "objectID": "PropensityScore.html",
    "href": "PropensityScore.html",
    "title": "倾向性评分",
    "section": "",
    "text": "分类\n倾向性评分只是一个分数（P值），自己并没有均衡协变量（混杂因素）的能力，利用 PS 值均衡组间协变量分布的方法有匹配（matching）、分层（stratification）、协变量调整（covariate adjustment）和加权（weighting）等。其中协变量调整又可以称为倾向性评分回归、倾向性评分矫正等。",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#预处理",
    "href": "PropensityScore.html#预处理",
    "title": "倾向性评分",
    "section": "预处理",
    "text": "预处理\n用于倾向性评分的数据要进行一些预处理，比如因子化 和 缺失值处理 如算法插补（KNN、随机森林等），",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PropensityScore.html#流程",
    "href": "PropensityScore.html#流程",
    "title": "倾向性评分",
    "section": "流程",
    "text": "流程\n倾向性评分的一般步骤为：\n\n\n选择倾向得分估计模型\n\n估计倾向得分：倾向得分是给定一组观察到的 covaraites 接受治疗、干预或暴露的条件概率 。PS 值的估计是以处理因素作为因变量，其他混杂因素作为自变量，通过建立一个模型来估计每个研究对象接受处理因素的可能性。目前用于估计 PS 值的方法有logistic 回归，分类树，Probit 回归、Bootstrapping、随机森林等。其中 logistic 回归是目前最常用的方法。\n平衡诊断 balance diagnosis：对于处理单元和对照单元成对的匹配方法，可以使用相关样本检验（例如，连续变量的 t 检验和分类变量的卡方检验），但是犯 I 类和 II 类错误的可能性非常高。\n\nPSAgraphics标准化的效应大小和图形表示，建议effect sizes小于 0.1。 连续变量的平衡诊断箱线图，分类变量的条形图\n\n重复前2步，直到优化足够的平衡\n\n\n\n估计因果关系\n因果关系的反事实模型\n因果推断的基本难题：Y=ZY1 +(1-Z)Y0 , Z=0 或 1，2个实际结果，2个反事实结果\n个体处理效应：\n\\[\nITE=\\tau_i=y_i^1-y_i^0\n\\]\nRubin’s Causal Model\n平均处理效应 Average Treatment Effect (ATE)\n\\[\n\\widehat {ATE} =E(\\tau)=E(Y^1-Y^0)=E(Y^1)-E(Y^0)\n\\]\nAverage Treatment Effect Among the Treated (ATT)\n\\[\n\\widehat {ATT} =E(Y^1-Y^0|X=1)=E(Y^1|X=1)-E(Y^0|X=1)\n\\]\nAverage Treatment Effect Among the Control (ATC)\n\\[\n\\widehat {ATC} =E(Y^1-Y^0|X=0)=E(Y^1|X=0)-E(Y^0|X=0)\n\\]\nAverage Treatment Effect Among the Evenly Matched (ATM) 专为倾向得分加权开发的相对较新的估计值，但与进行一对一匹配时的估计值密切相关。\n\\[\nATM_d=E(Y_1-Y_0|M_d=1)\n\\]\n进行 PSA 之前，将倾向得分（PS）与结果（outcome）根据治疗、干预或暴露（group）作图通常很有帮助。 Loess 回归线散点图\n分五层的倾向得分评估图，相关样本评估图\n\n\n敏感性分析： 检查未观察到的混杂因素confounding factor 的敏感性\n评估因果估计的稳健性\n\n敏感度分析：仅针对匹配方法进行了明确定义\n自举法：PSAboot",
    "crumbs": [
      "倾向性评分"
    ]
  },
  {
    "objectID": "PSM.html",
    "href": "PSM.html",
    "title": "\n1  PSM\n",
    "section": "",
    "text": "1.1 数据\nShow the code####################       数据模拟     ################################\n\n# 模拟了吸烟与心血管疾病 （CVD） 之间的关系，其中年龄和性别是潜在的混杂协变量\n\n# CVD 是结果变量（当患者没有 CVD 时，CVD = 0;否则，CVD =1）。\n# 吸烟是一个二进制变量，表示患者是否吸烟。性别（0 = 女性，1 = 男性）和年龄是两个混杂的协变量\n\n\nx.Gender &lt;-rep(0:1,c(400,600))# 400 females and 600 males\n\nset.seed(2020)\nx.Age &lt;-round(abs(rnorm(1000,mean=45,sd=15)))\n\n\n# 模拟数据的真实PS值\nz&lt;-(x.Age-45)/15-(x.Age-45)^2/100+2*x.Gender\ntps &lt;- exp(z)/(1+exp(z)) # The true PS\n\nset.seed(123)\nSmoke &lt;- as.numeric(runif(1000)&lt; tps)\n\nz.y&lt;-x.Gender +0.3*x.Age +5*Smoke-20\ny&lt;- exp(z.y)/(1+exp(z.y))\nset.seed(123)\nCVD &lt;- as.numeric(runif(1000)&lt; y)\n\nset.seed(124)\nx.Age.mask &lt;-rbinom(1000, 1,0.2)# Missing completely at random\nx.Age &lt;- ifelse(x.Age.mask==1,NA, x.Age)\n\n\ndata &lt;-data.frame(x.Age,x.Gender, Smoke, CVD)\nhead(data)\n#&gt;   x.Age x.Gender Smoke CVD\n#&gt; 1    51        0     1   1\n#&gt; 2    50        0     0   0\n#&gt; 3    29        0     0   0\n#&gt; 4    28        0     0   0\n#&gt; 5     3        0     0   0\n#&gt; 6    56        0     1   1\n\nlibrary(tableone)\ntbl1 &lt;- CreateTableOne(vars = c(\"x.Age\",\"x.Gender\",\"CVD\"),\n                       data = data,\n                       factorVars = c(\"x.Gender\",\"CVD\"),\n                       strata = \"Smoke\",smd = T)\n\ntbl1 &lt;- print(tbl1, showAllLevels = T, smd = T)\n#&gt;                    Stratified by Smoke\n#&gt;                     level 0             1             p      test SMD   \n#&gt;   n                         546           454                           \n#&gt;   x.Age (mean (SD))       43.30 (19.09) 46.73 (8.32)   0.001       0.233\n#&gt;   x.Gender (%)      0       297 (54.4)    103 (22.7)  &lt;0.001       0.689\n#&gt;                     1       249 (45.6)    351 (77.3)                    \n#&gt;   CVD (%)           0       470 (86.1)    204 (44.9)  &lt;0.001       0.960\n#&gt;                     1        76 (13.9)    250 (55.1)\ntbl1\n#&gt;                    Stratified by Smoke\n#&gt;                     level 0               1               p        test\n#&gt;   n                 \"\"    \"  546\"         \"  454\"         \"\"       \"\"  \n#&gt;   x.Age (mean (SD)) \"\"    \"43.30 (19.09)\" \"46.73 (8.32)\"  \" 0.001\" \"\"  \n#&gt;   x.Gender (%)      \"0\"   \"  297 (54.4) \" \"  103 (22.7) \" \"&lt;0.001\" \"\"  \n#&gt;                     \"1\"   \"  249 (45.6) \" \"  351 (77.3) \" \"\"       \"\"  \n#&gt;   CVD (%)           \"0\"   \"  470 (86.1) \" \"  204 (44.9) \" \"&lt;0.001\" \"\"  \n#&gt;                     \"1\"   \"   76 (13.9) \" \"  250 (55.1) \" \"\"       \"\"  \n#&gt;                    Stratified by Smoke\n#&gt;                     SMD     \n#&gt;   n                 \"\"      \n#&gt;   x.Age (mean (SD)) \" 0.233\"\n#&gt;   x.Gender (%)      \" 0.689\"\n#&gt;                     \"\"      \n#&gt;   CVD (%)           \" 0.960\"\n#&gt;                     \"\"\n# 吸烟组和非吸烟组之间的年龄和性别协变量存在显著差异\n\n\n\n######################################## 缺失值处理和数据整洁          ################\n\nmap_df(data, ~sum(is.na(.x)))\n#&gt; # A tibble: 1 × 4\n#&gt;   x.Age x.Gender Smoke   CVD\n#&gt;   &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n#&gt; 1   185        0     0     0\n\n# Gmd 是指基尼均值差\nHmisc::describe(data)\n#&gt; data \n#&gt; \n#&gt;  4  Variables      1000  Observations\n#&gt; --------------------------------------------------------------------------------\n#&gt; x.Age \n#&gt;        n  missing distinct     Info     Mean      Gmd      .05      .10 \n#&gt;      815      185       83        1    44.83    17.22       20       26 \n#&gt;      .25      .50      .75      .90      .95 \n#&gt;       35       44       55       64       70 \n#&gt; \n#&gt; lowest :   1   2   3   5   6, highest:  84  85  86  93 101\n#&gt; --------------------------------------------------------------------------------\n#&gt; x.Gender \n#&gt;        n  missing distinct     Info      Sum     Mean      Gmd \n#&gt;     1000        0        2     0.72      600      0.6   0.4805 \n#&gt; \n#&gt; --------------------------------------------------------------------------------\n#&gt; Smoke \n#&gt;        n  missing distinct     Info      Sum     Mean      Gmd \n#&gt;     1000        0        2    0.744      454    0.454   0.4963 \n#&gt; \n#&gt; --------------------------------------------------------------------------------\n#&gt; CVD \n#&gt;        n  missing distinct     Info      Sum     Mean      Gmd \n#&gt;     1000        0        2    0.659      326    0.326   0.4399 \n#&gt; \n#&gt; --------------------------------------------------------------------------------\n\nlibrary(VIM)\n\nset.seed(123)\ndata_knnimp &lt;- kNN(data = data, k = 10, weights = \"auto\", imp_var = F)\nmap_df(data_knnimp, ~sum(is.na(.x)))\n#&gt; # A tibble: 1 × 4\n#&gt;   x.Age x.Gender Smoke   CVD\n#&gt;   &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n#&gt; 1     0        0     0     0\n\ndata&lt;- data_knnimp %&gt;% \n    mutate(across(-x.Age,as.factor))",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#ps估计模型-distance",
    "href": "PSM.html#ps估计模型-distance",
    "title": "\n1  PSM\n",
    "section": "\n1.2 PS估计模型 distance\n",
    "text": "1.2 PS估计模型 distance\n\n\n1.2.1 逻辑回归\n\nShow the code############################      ########################\nlibrary(MatchIt)\n\nglm(formula = Smoke ~ x.Age + x.Gender, family = binomial(\"logit\") ,data = data)\n#&gt; \n#&gt; Call:  glm(formula = Smoke ~ x.Age + x.Gender, family = binomial(\"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        x.Age    x.Gender1  \n#&gt;    -1.98523      0.02005      1.44400  \n#&gt; \n#&gt; Degrees of Freedom: 999 Total (i.e. Null);  997 Residual\n#&gt; Null Deviance:       1378 \n#&gt; Residual Deviance: 1252  AIC: 1258\n\n\nm.out &lt;- matchit(formula = Smoke ~ x.Age + x.Gender, data = data)\nm.out$model\n#&gt; \n#&gt; Call:  glm(formula = Smoke ~ x.Age + x.Gender, family = structure(list(\n#&gt;     family = \"quasibinomial\", link = \"logit\", linkfun = function (mu) \n#&gt;     .Call(C_logit_link, mu), linkinv = function (eta) \n#&gt;     .Call(C_logit_linkinv, eta), variance = function (mu) \n#&gt;     mu * (1 - mu), dev.resids = function (y, mu, wt) \n#&gt;     .Call(C_binomial_dev_resids, y, mu, wt), aic = function (y, \n#&gt;         n, mu, wt, dev) \n#&gt;     NA, mu.eta = function (eta) \n#&gt;     .Call(C_logit_mu_eta, eta), initialize = {\n#&gt;         if (NCOL(y) == 1) {\n#&gt;             if (is.factor(y)) \n#&gt;                 y &lt;- y != levels(y)[1L]\n#&gt;             n &lt;- rep.int(1, nobs)\n#&gt;             y[weights == 0] &lt;- 0\n#&gt;             if (any(y &lt; 0 | y &gt; 1)) \n#&gt;                 stop(\"y values must be 0 &lt;= y &lt;= 1\")\n#&gt;             mustart &lt;- (weights * y + 0.5)/(weights + 1)\n#&gt;             m &lt;- weights * y\n#&gt;             if (\"quasibinomial\" == \"binomial\" && any(abs(m - \n#&gt;                 round(m)) &gt; 0.001)) \n#&gt;                 warning(gettextf(\"non-integer #successes in a %s glm!\", \n#&gt;                   \"quasibinomial\"), domain = NA)\n#&gt;         }\n#&gt;         else if (NCOL(y) == 2) {\n#&gt;             if (\"quasibinomial\" == \"binomial\" && any(abs(y - \n#&gt;                 round(y)) &gt; 0.001)) \n#&gt;                 warning(gettextf(\"non-integer counts in a %s glm!\", \n#&gt;                   \"quasibinomial\"), domain = NA)\n#&gt;             n &lt;- (y1 &lt;- y[, 1L]) + y[, 2L]\n#&gt;             y &lt;- y1/n\n#&gt;             if (any(n0 &lt;- n == 0)) \n#&gt;                 y[n0] &lt;- 0\n#&gt;             weights &lt;- weights * n\n#&gt;             mustart &lt;- (n * y + 0.5)/(n + 1)\n#&gt;         }\n#&gt;         else stop(gettextf(\"for the '%s' family, y must be a vector of 0 and 1's\\nor a 2 column matrix where col 1 is no. successes and col 2 is no. failures\", \n#&gt;             \"quasibinomial\"), domain = NA)\n#&gt;     }, validmu = function (mu) \n#&gt;     all(is.finite(mu)) && all(0 &lt; mu & mu &lt; 1), valideta = function (eta) \n#&gt;     TRUE, dispersion = NA_real_), class = \"family\"), data = structure(list(\n#&gt;     x.Age = c(51, 50, 29, 28, 3, 56, 59, 42, 78, 47, 32, 37, \n#&gt;     63, 37, 43, 72, 71, 1, 37, 46, 78, 61, 50, 44, 58, 48, 37, \n#&gt;     59, 45, 47, 37, 34, 61, 78, 51, 45, 41, 51, 37, 52, 59, 37, \n#&gt;     40, 34, 27, 49, 45, 45, 55, 52, 42, 51, 35, 52, 47, 47, 42, \n#&gt;     25, 36, 54, 74, 49, 21, 93, 59, 51, 59, 42, 46, 48, 57, 78, \n#&gt;     37, 51, 31, 34, 18, 37, 46, 49, 54, 45, 78, 48, 30, 78, 17, \n#&gt;     61, 73, 53, 22, 16, 52, 64, 42, 33, 50, 55, 37, 35, 19, 30, \n#&gt;     36, 51, 56, 37, 40, 37, 49, 49, 40, 67, 60, 37, 49, 33, 27, \n#&gt;     26, 43, 78, 40, 51, 78, 37, 26, 48, 56, 78, 78, 31, 47, 36, \n#&gt;     44, 43, 29, 44, 71, 37, 85, 26, 45, 44, 78, 15, 52, 41, 28, \n#&gt;     48, 46, 37, 40, 37, 45, 23, 51, 45, 28, 46, 35, 55, 54, 37, \n#&gt;     37, 45, 16, 64, 50, 32, 17, 58, 64, 49, 37, 37, 37, 37, 37, \n#&gt;     27, 61, 45, 41, 58, 29, 19, 81, 42, 59, 34, 26, 58, 63, 27, \n#&gt;     56, 58, 37, 54, 29, 37, 51, 55, 34, 37, 39, 37, 37, 26, 62, \n#&gt;     61, 44, 37, 53, 41, 78, 34, 52, 37, 30, 37, 28, 37, 53, 24, \n#&gt;     43, 37, 33, 51, 62, 52, 37, 45, 53, 52, 20, 70, 6, 57, 52, \n#&gt;     55, 51, 70, 46, 45, 78, 69, 47, 41, 15, 67, 37, 33, 45, 36, \n#&gt;     68, 28, 26, 37, 64, 47, 51, 57, 37, 20, 42, 53, 43, 37, 22, \n#&gt;     44, 60, 40, 37, 27, 36, 37, 9, 79, 37, 48, 32, 25, 47, 3, \n#&gt;     56, 33, 61, 39, 51, 60, 58, 13, 2, 36, 64, 42, 50, 35, 37, \n#&gt;     78, 37, 36, 59, 42, 63, 68, 67, 80, 78, 58, 47, 37, 46, 45, \n#&gt;     48, 51, 44, 38, 42, 27, 37, 53, 47, 37, 41, 57, 55, 46, 15, \n#&gt;     51, 59, 71, 40, 57, 38, 23, 37, 73, 46, 37, 39, 37, 25, 34, \n#&gt;     30, 47, 56, 28, 48, 43, 47, 35, 32, 43, 53, 39, 40, 43, 35, \n#&gt;     37, 70, 35, 51, 7, 27, 43, 55, 44, 84, 43, 51, 37, 60, 39, \n#&gt;     48, 51, 45, 52, 78, 37, 30, 29, 73, 43, 35, 37, 28, 54, 21, \n#&gt;     27, 63, 36, 55, 52, 45, 41, 45, 59, 72, 45, 45, 37, 33.5, \n#&gt;     50, 61, 41, 41, 41, 48, 11, 34, 42, 41, 41, 40, 50, 42, 43, \n#&gt;     61, 35, 25, 41, 59, 17, 46, 50, 51, 41, 27, 41, 41, 37, 53, \n#&gt;     36, 57, 30, 60, 50, 42, 47, 32, 40, 35, 46, 33.5, 68, 54, \n#&gt;     41, 36, 29, 67, 37, 36, 59, 40, 50, 50, 41, 46, 33, 50, 45, \n#&gt;     65, 50, 50, 64, 41, 63, 53, 21, 41, 40, 43, 33.5, 41, 37, \n#&gt;     50, 33, 43, 16, 68, 41, 31, 55, 42, 42, 42, 55, 66, 44, 33.5, \n#&gt;     43, 31, 68, 38, 51, 22, 45, 41, 41, 45, 79, 63, 45, 63, 47, \n#&gt;     68, 41, 39, 5, 21, 60, 16, 67, 46, 54, 35, 41, 43, 46, 45, \n#&gt;     44, 47, 53, 38, 43, 32, 25, 23, 51, 57, 50, 69, 63, 56, 53, \n#&gt;     40, 19, 44, 39, 41, 41, 36, 33, 50, 43, 78, 33.5, 39, 43, \n#&gt;     59, 41, 55, 41, 41, 26, 54, 38, 70, 60, 42, 48, 24, 33.5, \n#&gt;     36, 47, 50, 68, 41, 54, 82, 33, 41, 54, 51, 59, 25, 33.5, \n#&gt;     82, 52, 26, 22, 35, 74, 41, 41, 53, 29, 51, 53, 33.5, 40, \n#&gt;     14, 40, 63, 50, 48, 45, 38, 22, 59, 65, 49, 78, 50, 25, 50, \n#&gt;     60, 37, 50, 42, 45, 52, 50, 29, 33.5, 32, 58, 52, 68, 43, \n#&gt;     52, 69, 32, 47, 50, 28, 50, 46, 18, 50, 50, 41, 33.5, 20, \n#&gt;     61, 41, 40, 13, 28, 49, 27, 53, 62, 33.5, 37, 51, 40, 64, \n#&gt;     82, 57, 45, 22, 33.5, 33.5, 72, 42, 55, 30, 39, 21, 40, 34, \n#&gt;     33.5, 50, 11, 50, 21, 52, 34, 49, 48, 44, 25, 52, 26, 43, \n#&gt;     73, 61, 34, 35, 67, 18, 44, 42, 43, 25, 41, 47, 60, 50, 42, \n#&gt;     32, 27, 26, 56, 54, 24, 50, 44, 20, 41, 47, 47, 39, 38, 56, \n#&gt;     40, 36, 60, 59, 28, 79, 35, 29, 47, 101, 69, 50, 63, 54, \n#&gt;     56, 78, 39, 70, 37, 49, 50, 31, 37, 41, 55, 69, 40, 44, 37, \n#&gt;     33, 31, 67, 24, 41, 41, 68, 37, 50, 51, 67, 42, 41, 50, 44, \n#&gt;     31, 81, 52, 33.5, 29, 32, 51, 33, 33.5, 39, 71, 57, 57, 63, \n#&gt;     62, 65, 34, 55, 34, 2, 18, 57, 43, 63, 57, 59, 35, 41, 50, \n#&gt;     28, 46, 37, 33.5, 40, 52, 11, 33, 50, 50, 56, 48, 39, 50, \n#&gt;     33, 50, 73, 39, 26, 48, 54, 69, 51, 50, 45, 57, 56, 48, 27, \n#&gt;     33.5, 51, 23, 33.5, 66, 39, 40, 23, 45, 26, 84, 54, 49, 64, \n#&gt;     47, 47, 13, 66, 20, 40, 41, 39, 50, 41, 69, 48, 59, 35, 51, \n#&gt;     33.5, 35, 47, 54, 30, 56, 34, 41, 50, 76, 33.5, 47, 41, 44, \n#&gt;     58, 59, 44, 33.5, 31, 40, 43, 56, 50, 33.5, 54, 58, 52, 50, \n#&gt;     34, 41, 51, 38, 69, 53, 41, 31, 40, 34, 33.5, 49, 34, 41, \n#&gt;     22, 43, 54, 51, 42, 57, 48, 40, 65, 33, 27, 50, 69, 77, 31, \n#&gt;     45, 60, 20, 59, 50, 50, 32, 33.5, 55, 55, 56, 26, 67, 46, \n#&gt;     33.5, 40, 33, 30, 41, 57, 73, 20, 40, 26, 33.5, 49, 33.5, \n#&gt;     34, 65, 50, 41, 37, 66, 41, 50, 50, 30, 33, 41, 49, 48, 37, \n#&gt;     64, 32, 42, 48, 22, 33.5, 35, 34, 24, 41, 51, 86, 33.5, 41, \n#&gt;     35, 55, 50, 57, 8, 41, 41, 61, 23, 43, 54, 27, 50, 58, 31, \n#&gt;     46, 43, 52, 41, 51, 43, 41, 50, 58, 39, 41, 33.5, 35, 23, \n#&gt;     42, 50, 19, 33, 32, 64, 25, 36, 63, 20, 24, 34, 82, 36, 41, \n#&gt;     33.5, 51, 43, 70, 39, 57, 31), x.Gender = structure(c(1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), levels = c(\"0\", \"1\"), class = \"factor\"), \n#&gt;     Smoke = structure(c(2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L\n#&gt;     ), levels = c(\"0\", \"1\"), class = \"factor\"), CVD = structure(c(2L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), levels = c(\"0\", \"1\"), class = \"factor\")), row.names = c(NA, \n#&gt; -1000L), class = \"data.frame\"))\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        x.Age    x.Gender1  \n#&gt;    -1.98523      0.02005      1.44400  \n#&gt; \n#&gt; Degrees of Freedom: 999 Total (i.e. Null);  997 Residual\n#&gt; Null Deviance:       1378 \n#&gt; Residual Deviance: 1252  AIC: NA\n\n# 估计的PS值\neps &lt;- m.out$distance\n\n# 模拟数据的真实PS值\nz&lt;-(x.Age-45)/15-(x.Age-45)^2/100+2*x.Gender\n\ntps &lt;- exp(z)/(1+exp(z)) # The true PS\ntps_comp &lt;- tps[complete.cases(data)]\n\nsmoke_comp &lt;- Smoke[complete.cases(data)] %&gt;% as.factor()\n\ndf &lt;- tibble(\n    True = tps_comp,\n    Estimate = eps,  # 估计如此糟糕（就像 sin 函数一样），是因为我们通过二次方程生成 PS\n    smoke= smoke_comp\n)\ndf\n#&gt; # A tibble: 1,000 × 3\n#&gt;        True Estimate smoke\n#&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;\n#&gt;  1  5.10e-1    0.276 1    \n#&gt;  2  5.21e-1    0.272 0    \n#&gt;  3  2.59e-2    0.197 0    \n#&gt;  4  1.76e-2    0.194 0    \n#&gt;  5  1.33e-9    0.127 0    \n#&gt;  6  3.83e-1    0.297 1    \n#&gt;  7  2.64e-1    0.310 0    \n#&gt;  8  4.28e-1    0.242 0    \n#&gt;  9 NA          0.396 0    \n#&gt; 10  5.23e-1    0.261 1    \n#&gt; # ℹ 990 more rows\n\nggplot(df, aes(True, Estimate, colour = smoke))+\n    geom_point()+\n    geom_abline(intercept = 0,slope = 1,color = \"#990000\",\n                linetype= \"dashed\")\n\n\n\n\n\n\nShow the code\n\nm.out2 &lt;- matchit(formula = Smoke ~ x.Age + I(x.Age^2) + x.Gender, data = data)\n\neps2 &lt;- m.out2$distance\ndf &lt;- tibble(\n    True = tps_comp,\n    Estimate = eps2,  # 估计如此糟糕（就像 sin 函数一样），是因为我们通过二次方程生成 PS\n    smoke= smoke_comp\n)\nggplot(df, aes(True, Estimate, colour = smoke))+\n    geom_point()+\n    geom_abline(intercept = 0,slope = 1,color = \"#990000\",\n                linetype= \"dashed\")\n\n\n\n\n\n\nShow the code\nm.out2$model\n#&gt; \n#&gt; Call:  glm(formula = Smoke ~ x.Age + I(x.Age^2) + x.Gender, family = structure(list(\n#&gt;     family = \"quasibinomial\", link = \"logit\", linkfun = function (mu) \n#&gt;     .Call(C_logit_link, mu), linkinv = function (eta) \n#&gt;     .Call(C_logit_linkinv, eta), variance = function (mu) \n#&gt;     mu * (1 - mu), dev.resids = function (y, mu, wt) \n#&gt;     .Call(C_binomial_dev_resids, y, mu, wt), aic = function (y, \n#&gt;         n, mu, wt, dev) \n#&gt;     NA, mu.eta = function (eta) \n#&gt;     .Call(C_logit_mu_eta, eta), initialize = {\n#&gt;         if (NCOL(y) == 1) {\n#&gt;             if (is.factor(y)) \n#&gt;                 y &lt;- y != levels(y)[1L]\n#&gt;             n &lt;- rep.int(1, nobs)\n#&gt;             y[weights == 0] &lt;- 0\n#&gt;             if (any(y &lt; 0 | y &gt; 1)) \n#&gt;                 stop(\"y values must be 0 &lt;= y &lt;= 1\")\n#&gt;             mustart &lt;- (weights * y + 0.5)/(weights + 1)\n#&gt;             m &lt;- weights * y\n#&gt;             if (\"quasibinomial\" == \"binomial\" && any(abs(m - \n#&gt;                 round(m)) &gt; 0.001)) \n#&gt;                 warning(gettextf(\"non-integer #successes in a %s glm!\", \n#&gt;                   \"quasibinomial\"), domain = NA)\n#&gt;         }\n#&gt;         else if (NCOL(y) == 2) {\n#&gt;             if (\"quasibinomial\" == \"binomial\" && any(abs(y - \n#&gt;                 round(y)) &gt; 0.001)) \n#&gt;                 warning(gettextf(\"non-integer counts in a %s glm!\", \n#&gt;                   \"quasibinomial\"), domain = NA)\n#&gt;             n &lt;- (y1 &lt;- y[, 1L]) + y[, 2L]\n#&gt;             y &lt;- y1/n\n#&gt;             if (any(n0 &lt;- n == 0)) \n#&gt;                 y[n0] &lt;- 0\n#&gt;             weights &lt;- weights * n\n#&gt;             mustart &lt;- (n * y + 0.5)/(n + 1)\n#&gt;         }\n#&gt;         else stop(gettextf(\"for the '%s' family, y must be a vector of 0 and 1's\\nor a 2 column matrix where col 1 is no. successes and col 2 is no. failures\", \n#&gt;             \"quasibinomial\"), domain = NA)\n#&gt;     }, validmu = function (mu) \n#&gt;     all(is.finite(mu)) && all(0 &lt; mu & mu &lt; 1), valideta = function (eta) \n#&gt;     TRUE, dispersion = NA_real_), class = \"family\"), data = structure(list(\n#&gt;     x.Age = c(51, 50, 29, 28, 3, 56, 59, 42, 78, 47, 32, 37, \n#&gt;     63, 37, 43, 72, 71, 1, 37, 46, 78, 61, 50, 44, 58, 48, 37, \n#&gt;     59, 45, 47, 37, 34, 61, 78, 51, 45, 41, 51, 37, 52, 59, 37, \n#&gt;     40, 34, 27, 49, 45, 45, 55, 52, 42, 51, 35, 52, 47, 47, 42, \n#&gt;     25, 36, 54, 74, 49, 21, 93, 59, 51, 59, 42, 46, 48, 57, 78, \n#&gt;     37, 51, 31, 34, 18, 37, 46, 49, 54, 45, 78, 48, 30, 78, 17, \n#&gt;     61, 73, 53, 22, 16, 52, 64, 42, 33, 50, 55, 37, 35, 19, 30, \n#&gt;     36, 51, 56, 37, 40, 37, 49, 49, 40, 67, 60, 37, 49, 33, 27, \n#&gt;     26, 43, 78, 40, 51, 78, 37, 26, 48, 56, 78, 78, 31, 47, 36, \n#&gt;     44, 43, 29, 44, 71, 37, 85, 26, 45, 44, 78, 15, 52, 41, 28, \n#&gt;     48, 46, 37, 40, 37, 45, 23, 51, 45, 28, 46, 35, 55, 54, 37, \n#&gt;     37, 45, 16, 64, 50, 32, 17, 58, 64, 49, 37, 37, 37, 37, 37, \n#&gt;     27, 61, 45, 41, 58, 29, 19, 81, 42, 59, 34, 26, 58, 63, 27, \n#&gt;     56, 58, 37, 54, 29, 37, 51, 55, 34, 37, 39, 37, 37, 26, 62, \n#&gt;     61, 44, 37, 53, 41, 78, 34, 52, 37, 30, 37, 28, 37, 53, 24, \n#&gt;     43, 37, 33, 51, 62, 52, 37, 45, 53, 52, 20, 70, 6, 57, 52, \n#&gt;     55, 51, 70, 46, 45, 78, 69, 47, 41, 15, 67, 37, 33, 45, 36, \n#&gt;     68, 28, 26, 37, 64, 47, 51, 57, 37, 20, 42, 53, 43, 37, 22, \n#&gt;     44, 60, 40, 37, 27, 36, 37, 9, 79, 37, 48, 32, 25, 47, 3, \n#&gt;     56, 33, 61, 39, 51, 60, 58, 13, 2, 36, 64, 42, 50, 35, 37, \n#&gt;     78, 37, 36, 59, 42, 63, 68, 67, 80, 78, 58, 47, 37, 46, 45, \n#&gt;     48, 51, 44, 38, 42, 27, 37, 53, 47, 37, 41, 57, 55, 46, 15, \n#&gt;     51, 59, 71, 40, 57, 38, 23, 37, 73, 46, 37, 39, 37, 25, 34, \n#&gt;     30, 47, 56, 28, 48, 43, 47, 35, 32, 43, 53, 39, 40, 43, 35, \n#&gt;     37, 70, 35, 51, 7, 27, 43, 55, 44, 84, 43, 51, 37, 60, 39, \n#&gt;     48, 51, 45, 52, 78, 37, 30, 29, 73, 43, 35, 37, 28, 54, 21, \n#&gt;     27, 63, 36, 55, 52, 45, 41, 45, 59, 72, 45, 45, 37, 33.5, \n#&gt;     50, 61, 41, 41, 41, 48, 11, 34, 42, 41, 41, 40, 50, 42, 43, \n#&gt;     61, 35, 25, 41, 59, 17, 46, 50, 51, 41, 27, 41, 41, 37, 53, \n#&gt;     36, 57, 30, 60, 50, 42, 47, 32, 40, 35, 46, 33.5, 68, 54, \n#&gt;     41, 36, 29, 67, 37, 36, 59, 40, 50, 50, 41, 46, 33, 50, 45, \n#&gt;     65, 50, 50, 64, 41, 63, 53, 21, 41, 40, 43, 33.5, 41, 37, \n#&gt;     50, 33, 43, 16, 68, 41, 31, 55, 42, 42, 42, 55, 66, 44, 33.5, \n#&gt;     43, 31, 68, 38, 51, 22, 45, 41, 41, 45, 79, 63, 45, 63, 47, \n#&gt;     68, 41, 39, 5, 21, 60, 16, 67, 46, 54, 35, 41, 43, 46, 45, \n#&gt;     44, 47, 53, 38, 43, 32, 25, 23, 51, 57, 50, 69, 63, 56, 53, \n#&gt;     40, 19, 44, 39, 41, 41, 36, 33, 50, 43, 78, 33.5, 39, 43, \n#&gt;     59, 41, 55, 41, 41, 26, 54, 38, 70, 60, 42, 48, 24, 33.5, \n#&gt;     36, 47, 50, 68, 41, 54, 82, 33, 41, 54, 51, 59, 25, 33.5, \n#&gt;     82, 52, 26, 22, 35, 74, 41, 41, 53, 29, 51, 53, 33.5, 40, \n#&gt;     14, 40, 63, 50, 48, 45, 38, 22, 59, 65, 49, 78, 50, 25, 50, \n#&gt;     60, 37, 50, 42, 45, 52, 50, 29, 33.5, 32, 58, 52, 68, 43, \n#&gt;     52, 69, 32, 47, 50, 28, 50, 46, 18, 50, 50, 41, 33.5, 20, \n#&gt;     61, 41, 40, 13, 28, 49, 27, 53, 62, 33.5, 37, 51, 40, 64, \n#&gt;     82, 57, 45, 22, 33.5, 33.5, 72, 42, 55, 30, 39, 21, 40, 34, \n#&gt;     33.5, 50, 11, 50, 21, 52, 34, 49, 48, 44, 25, 52, 26, 43, \n#&gt;     73, 61, 34, 35, 67, 18, 44, 42, 43, 25, 41, 47, 60, 50, 42, \n#&gt;     32, 27, 26, 56, 54, 24, 50, 44, 20, 41, 47, 47, 39, 38, 56, \n#&gt;     40, 36, 60, 59, 28, 79, 35, 29, 47, 101, 69, 50, 63, 54, \n#&gt;     56, 78, 39, 70, 37, 49, 50, 31, 37, 41, 55, 69, 40, 44, 37, \n#&gt;     33, 31, 67, 24, 41, 41, 68, 37, 50, 51, 67, 42, 41, 50, 44, \n#&gt;     31, 81, 52, 33.5, 29, 32, 51, 33, 33.5, 39, 71, 57, 57, 63, \n#&gt;     62, 65, 34, 55, 34, 2, 18, 57, 43, 63, 57, 59, 35, 41, 50, \n#&gt;     28, 46, 37, 33.5, 40, 52, 11, 33, 50, 50, 56, 48, 39, 50, \n#&gt;     33, 50, 73, 39, 26, 48, 54, 69, 51, 50, 45, 57, 56, 48, 27, \n#&gt;     33.5, 51, 23, 33.5, 66, 39, 40, 23, 45, 26, 84, 54, 49, 64, \n#&gt;     47, 47, 13, 66, 20, 40, 41, 39, 50, 41, 69, 48, 59, 35, 51, \n#&gt;     33.5, 35, 47, 54, 30, 56, 34, 41, 50, 76, 33.5, 47, 41, 44, \n#&gt;     58, 59, 44, 33.5, 31, 40, 43, 56, 50, 33.5, 54, 58, 52, 50, \n#&gt;     34, 41, 51, 38, 69, 53, 41, 31, 40, 34, 33.5, 49, 34, 41, \n#&gt;     22, 43, 54, 51, 42, 57, 48, 40, 65, 33, 27, 50, 69, 77, 31, \n#&gt;     45, 60, 20, 59, 50, 50, 32, 33.5, 55, 55, 56, 26, 67, 46, \n#&gt;     33.5, 40, 33, 30, 41, 57, 73, 20, 40, 26, 33.5, 49, 33.5, \n#&gt;     34, 65, 50, 41, 37, 66, 41, 50, 50, 30, 33, 41, 49, 48, 37, \n#&gt;     64, 32, 42, 48, 22, 33.5, 35, 34, 24, 41, 51, 86, 33.5, 41, \n#&gt;     35, 55, 50, 57, 8, 41, 41, 61, 23, 43, 54, 27, 50, 58, 31, \n#&gt;     46, 43, 52, 41, 51, 43, 41, 50, 58, 39, 41, 33.5, 35, 23, \n#&gt;     42, 50, 19, 33, 32, 64, 25, 36, 63, 20, 24, 34, 82, 36, 41, \n#&gt;     33.5, 51, 43, 70, 39, 57, 31), x.Gender = structure(c(1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), levels = c(\"0\", \"1\"), class = \"factor\"), \n#&gt;     Smoke = structure(c(2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n#&gt;     2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L\n#&gt;     ), levels = c(\"0\", \"1\"), class = \"factor\"), CVD = structure(c(2L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, \n#&gt;     2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, \n#&gt;     1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, \n#&gt;     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, \n#&gt;     2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, \n#&gt;     1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, \n#&gt;     2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, \n#&gt;     1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, \n#&gt;     2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, \n#&gt;     2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, \n#&gt;     1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), levels = c(\"0\", \"1\"), class = \"factor\")), row.names = c(NA, \n#&gt; -1000L), class = \"data.frame\"))\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        x.Age   I(x.Age^2)    x.Gender1  \n#&gt;   -28.99771      1.19555     -0.01223      2.12637  \n#&gt; \n#&gt; Degrees of Freedom: 999 Total (i.e. Null);  996 Residual\n#&gt; Null Deviance:       1378 \n#&gt; Residual Deviance: 819.7     AIC: NA\n\n\n\n1.2.2 分类和回归树\n\nShow the code########################## ##########\nm.out_rpart &lt;- matchit(formula = Smoke ~ x.Age + x.Gender, data = data,\n                distance = \"rpart\")\n\ntibble(True = tps_comp,\n       Estimate = m.out_rpart$distance,\n       smoke = smoke_comp) %&gt;%\n    ggplot(aes(True, Estimate, colour = smoke)) +\n    geom_point() +\n    geom_abline(\n        intercept = 0,\n        slope = 1,\n        color = \"#990000\",\n        linetype = \"dashed\"\n    )\n\n\n\n\n\n\nShow the code\nm.out_rpart2 &lt;- matchit(formula = Smoke ~ x.Age + I(x.Age^2) + x.Gender, data = data,\n                       distance = \"rpart\")\n\ntibble(True = tps_comp,\n       Estimate = m.out_rpart2$distance,\n       smoke = smoke_comp) %&gt;%\n    ggplot(aes(True, Estimate, colour = smoke)) +\n    geom_point() +\n    geom_abline(\n        intercept = 0,\n        slope = 1,\n        color = \"#990000\",\n        linetype = \"dashed\"\n    )\n\n\n\n\n\n\n\n\n1.2.3 随机森林\n\nShow the code############################# #################\n\nlibrary(randomForest)\nset.seed(123)\nrf_psm &lt;- randomForest(formula =  Smoke ~ x.Age + I(x.Age^2) + x.Gender, data =data)\n\nrf_psm\n#&gt; \n#&gt; Call:\n#&gt;  randomForest(formula = Smoke ~ x.Age + I(x.Age^2) + x.Gender,      data = data) \n#&gt;                Type of random forest: classification\n#&gt;                      Number of trees: 500\n#&gt; No. of variables tried at each split: 1\n#&gt; \n#&gt;         OOB estimate of  error rate: 18.7%\n#&gt; Confusion matrix:\n#&gt;     0   1 class.error\n#&gt; 0 445 101   0.1849817\n#&gt; 1  86 368   0.1894273\n\n\ntibble(True = tps_comp,\n       Estimate = rf_psm$votes[,2],\n       smoke = smoke_comp) %&gt;%\n    ggplot(aes(True, Estimate, colour = smoke)) +\n    geom_point() +\n    geom_abline(\n        intercept = 0,\n        slope = 1,\n        color = \"#990000\",\n        linetype = \"dashed\"\n    )",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#距离匹配算法-method",
    "href": "PSM.html#距离匹配算法-method",
    "title": "\n1  PSM\n",
    "section": "\n1.3 距离匹配算法 method\n",
    "text": "1.3 距离匹配算法 method\n\n\na caliper width of 0.2 of the standard deviation (SD) of the logit of PS be used\n\nShow the code#######  最近邻匹配 （NNM）      ##############\n\nlogit_knn_ratio &lt;- matchit(formula = Smoke ~ x.Age + x.Gender, data = data,\n                 method = \"nearest\", replace = T, ratio = 3)\n\nlogit_knn_ratio$match.matrix %&gt;% head()\n#&gt;    [,1]  [,2]  [,3] \n#&gt; 1  \"104\" \"295\" \"167\"\n#&gt; 6  \"105\" \"193\" \"283\"\n#&gt; 10 \"55\"  \"131\" \"281\"\n#&gt; 15 \"119\" \"134\" \"223\"\n#&gt; 29 \"82\"  \"180\" \"230\"\n#&gt; 30 \"55\"  \"131\" \"281\"\n\nlogit_knn_ratio$discarded %&gt;% sum() # 记录是否有丢弃的患者\n#&gt; [1] 0\n\n\n\n\n##########    最佳匹配 （OM）         #################\n\n\n\n\n###########      遗传匹配 （GM） 是 PSM的扩展     ################\n# 进化搜索算法\n# 当除 PS 之外的其他协变量的所有权重都设置为 0 时，GM 将等效于 PSM。\n\n\n\n\n\n\n\n\n\n\n#################  full matchin  #############3\n\n\n如果使用最佳匹配，则必须安装 optmatch 包，而基因匹配需要 rgenound 包。",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#平衡诊断",
    "href": "PSM.html#平衡诊断",
    "title": "\n1  PSM\n",
    "section": "\n1.4 平衡诊断",
    "text": "1.4 平衡诊断\n\n1.4.1 SMD 和 VR\n比较治疗组和对照组中协变量的标准化均数差 （SMD） 和方差比 （VR）\n\nSMD 值为 &lt;0.1 ，至少&lt;0.25。\nVR 是治疗组和对照组的方差比。接近 1.0 的 VR 表示协变量平衡，而 VR &lt;0.5 或 &gt;2.0 被认为“太极端”\n\n\nShow the codesummary(m.out, standardize = T)\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = Smoke ~ x.Age + x.Gender, data = data)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.5199        0.3992          0.8545     0.6324    0.1981\n#&gt; x.Age           46.6476       43.0769          0.4638     0.1743    0.1277\n#&gt; x.Gender0        0.2269        0.5440         -0.7571          .    0.3171\n#&gt; x.Gender1        0.7731        0.4560          0.7571          .    0.3171\n#&gt;           eCDF Max\n#&gt; distance    0.5027\n#&gt; x.Age       0.4217\n#&gt; x.Gender0   0.3171\n#&gt; x.Gender1   0.3171\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.5199        0.4402          0.5646     0.7389    0.1388\n#&gt; x.Age           46.6476       46.3062          0.0443     0.1857    0.1108\n#&gt; x.Gender0        0.2269        0.4537         -0.5417          .    0.2269\n#&gt; x.Gender1        0.7731        0.5463          0.5417          .    0.2269\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.4581          0.7250\n#&gt; x.Age       0.3282          2.2455\n#&gt; x.Gender0   0.2269          0.5417\n#&gt; x.Gender1   0.2269          0.5417\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           546     454\n#&gt; Matched       454     454\n#&gt; Unmatched      92       0\n#&gt; Discarded       0       0\n#  summary 命令不加选择地计算离散变量和连续变量的 SMD，从而导致离散变量的偏差(被视为连续变量以检查摘要中的smd)\n\n\n\n\nafter_match &lt;- match.data(m.out)\n\n# 由 CreateTableOne 函数汇总的匹配数据的基线协变量。\ntbl2 &lt;- CreateTableOne(vars = c(\"x.Age\",\"x.Gender\",\"CVD\"),\n                       data = after_match,\n                       factorVars = c(\"x.Gender\",\"CVD\"),\n                       strata = \"Smoke\",smd = T)\n# 此函数仅考虑匹配数据，并且均值差值由匹配数据 标准化（除以 SD）。匹配后，匹配数据中的标准差可能会更小，因此 SMD 可能比匹配前更大，尽管平均差值减小\nprint(tbl2, showAllLevels = T, smd = T)\n#&gt;                    Stratified by Smoke\n#&gt;                     level 0             1             p      test SMD   \n#&gt;   n                         454           454                           \n#&gt;   x.Age (mean (SD))       46.31 (17.87) 46.65 (7.70)   0.709       0.025\n#&gt;   x.Gender (%)      0       206 (45.4)    103 (22.7)  &lt;0.001       0.493\n#&gt;                     1       248 (54.6)    351 (77.3)                    \n#&gt;   CVD (%)           0       379 (83.5)    204 (44.9)  &lt;0.001       0.878\n#&gt;                     1        75 (16.5)    250 (55.1)\n\n\n更好的方法是使用原始 SD，它由 cobalt 包中的 bal.tab 函数实现\n\nShow the codeif(!require(cobalt)) install.packages(\"cobalt\")\n\nbal.tab(m.out, thresholds = c(m = 0.1, v = 2))\n#&gt; Balance Measures\n#&gt;              Type Diff.Adj        M.Threshold V.Ratio.Adj      V.Threshold\n#&gt; distance Distance   0.5646                         0.7389     Balanced, &lt;2\n#&gt; x.Age     Contin.   0.0443     Balanced, &lt;0.1      0.1857 Not Balanced, &gt;2\n#&gt; x.Gender   Binary   0.2269 Not Balanced, &gt;0.1           .                 \n#&gt; \n#&gt; Balance tally for mean differences\n#&gt;                    count\n#&gt; Balanced, &lt;0.1         1\n#&gt; Not Balanced, &gt;0.1     1\n#&gt; \n#&gt; Variable with the greatest mean difference\n#&gt;  Variable Diff.Adj        M.Threshold\n#&gt;  x.Gender   0.2269 Not Balanced, &gt;0.1\n#&gt; \n#&gt; Balance tally for variance ratios\n#&gt;                  count\n#&gt; Balanced, &lt;2         1\n#&gt; Not Balanced, &gt;2     1\n#&gt; \n#&gt; Variable with the greatest variance ratio\n#&gt;  Variable V.Ratio.Adj      V.Threshold\n#&gt;     x.Age      0.1857 Not Balanced, &gt;2\n#&gt; \n#&gt; Sample sizes\n#&gt;           Control Treated\n#&gt; All           546     454\n#&gt; Matched       454     454\n#&gt; Unmatched      92       0\n\n\n\n1.4.2 显著性检验\n\n有人批评 P 值的增加可能是由于 PSM 后研究人群的样本量减少 。应该使用解释匹配设计的统计数据，例如用于连续结果的配对 t 检验和 1：1 匹配设计中用于二分结果的 McNemar 检验 。这种做法很少在文献中实施或明确说明。\n\nShow the codehead(after_match)\n#&gt;   x.Age x.Gender Smoke CVD  distance weights subclass\n#&gt; 1    51        0     1   1 0.2763829       1        1\n#&gt; 2    50        0     0   0 0.2723902       1        3\n#&gt; 6    56        0     1   1 0.2968789       1      220\n#&gt; 7    59        0     0   0 0.3095888       1      247\n#&gt; 8    42        0     0   0 0.2417770       1       65\n#&gt; 9    78        0     0   1 0.3962738       1      355\n\n\nWeights 列是为每个样本提供的权重。这些权重是通过精心设计的规则计算的，以确保匹配的治疗组和对照组的权重相似。可以看出，1 名参与者（编号 7）被多次匹配，导出的数据中的权重为 0.187 。在这种情况下，可以通过使用weigts 包中带有 wtd.t.test() 函数的加权 t 检验来执行带有权重的统计\n\nShow the codeif(!require(weights, quietly = T)) install.packages(\"weights\")\nafter_match %&gt;% DT::datatable()\n\n\n\n\n\n\nShow the codeattach(after_match)\nage_trt &lt;- after_match[Smoke== 1, \"x.Age\"]\nweight_trt &lt;- after_match[Smoke== 1, \"weights\"]\n\nage_ctrl &lt;- after_match[Smoke== 0, \"x.Age\"]\nweight_ctrl &lt;- after_match[Smoke== 0, \"weights\"]\n\n\nwtd.t.test(x = age_ctrl, y = age_trt,\n        weight = weight_ctrl, weighty = weight_trt)\n#&gt; $test\n#&gt; [1] \"Two Sample Weighted T-Test (Welch)\"\n#&gt; \n#&gt; $coefficients\n#&gt;     t.value          df     p.value \n#&gt;  -0.1176369 848.0506954   0.9063832 \n#&gt; \n#&gt; $additional\n#&gt; Difference     Mean.x     Mean.y   Std. Err \n#&gt; -0.1085573 46.4285714 46.5371287  0.9228169\ndetach(after_match)\n\n\nt 检验，则应对协变量值的顺序进行排序\n\nShow the codematch_trt &lt;- data[rownames(m.out$match.matrix),]\n\nmatx &lt;- m.out$match.matrix\n\ndim(matx) &lt;- c(dim(matx)[1]* dim(matx)[2],1)\n\nmatch_ctrl &lt;- data[matx, ]\n\nt.test(match_ctrl$x.Age, match_trt$x.Age, paired = F)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  match_ctrl$x.Age and match_trt$x.Age\n#&gt; t = -0.3739, df = 615.61, p-value = 0.7086\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -2.134594  1.451775\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  46.30617  46.64758\n\n\nKolmogorov-Smirnov （KS） 统计\ncobalt 包中的函数 bal.tab 还提供 KS 检验，该检验比较处理组和对照组之间协变量的分布。唯一的要求是设置 ks.threshold 参数。\n\n1.4.3 分布可视化\n\n直方图、分位数-分位数图、累积分布函数 ，love plots\n\nShow the codeplot(m.out)\n\n\n\n\n\n\nShow the codeplot(m.out, type= \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\nplot(m.out, type= \"hist\")\n\n\n\n\n\n\nShow the code\n\nbal.plot(m.out,var.name = \"x.Age\", which = \"both\",\n         grid = T)\n\n\n\n\n\n\nShow the codebal.plot(m.out,var.name = \"x.Gender\", which = \"both\",\n         grid = T)\n\n\n\n\n\n\nShow the codebal.plot(m.out,var.name = \"x.Age\", which = \"both\",\n         grid = T, type = \"ecdf\")\n\n\n\n\n\n\nShow the code\n\nlove.plot(bal.tab(m.out, thresholds = c(m = 0.1, v = 2)),\n          grid = T, stars = \"raw\", \n          abs = F,stats = \"mean.diffs\"\n          )\n\n\n\n\n\n\n\n\n1.4.4 拟合优度指标\n\nc-statistics, or area under the receiver operating characteristic curve (AUROC)\n。但是，这些统计数据没有提供关于是否正确指定 PS 型号的信息\n\n1.4.5 如果协变量在匹配后仍然不平衡，该怎么办？\n\n更改公式 formula，甚至模型 distance ， 机器学习\n更改匹配方法 method，更改更小的卡尺 caliper = 0.1，pop.size=100 的 GM \n将 PSM 与精确匹配方法相结合 exact=c（'x.Gender'） ， 不推荐\n增加样本量\nPSM 后基线协变量的残差可以通过匹配、分层、回归调整等常规方法处理",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#非随机试验中的二分类治疗效果",
    "href": "PSM.html#非随机试验中的二分类治疗效果",
    "title": "\n1  PSM\n",
    "section": "\n1.5 非随机试验中的二分类治疗效果",
    "text": "1.5 非随机试验中的二分类治疗效果\n在 Rubin 提出的反事实框架下，对于每个个体，在治疗分配之前有两种潜在结果（在治疗或控制条件下）。一旦患者接受治疗或对照，研究人员就会观察到两种结果中的一种，但另一种结果缺失。在某种程度上，观察性研究中的数据分析就像缺失结果的插值。\nAbadie 和 Imbens 提出了一个适合匹配的治疗效果估计量。在匹配数据中，所有协变量在处理组和对照组之间具有相似的分布。这意味着匹配的患者被认为是相似的。使用匹配的对照组的平均结果对治疗组的缺失结果进行插值，反之亦然。假设接受治疗的患者具有平均结果 （A）。在估计 PS 并进行匹配后，我们将对照条件下接受治疗的患者的结局与匹配患者的结局进行插值。如果他们没有接受治疗，他们对结果的期望应该是 B。因此，我们在匹配数据上比较两个平均结果 （A vs. B），以估计对接受治疗的平均治疗效果。\nthe average treatment effect (ATE) and the average treatment effect on the treated (ATT).\n\n1.5.1 ATT\nZelig 包估计 Monte Carlo 模拟的因果效应,但Zelig 包不再维护更新\nTranslating Zelig to clarify\n\nShow the codelibrary(\"clarify\")\nafter_match &lt;- match.data(m.out)\n\nfit &lt;- glm(CVD ~ Smoke + x.Age + x.Gender, data = after_match,\n           family = binomial(link = \"logit\"),weights = after_match$weights )\n\n\nset.seed(123)\nsim_coefs &lt;- clarify::sim(fit)\nsim_coefs\n#&gt; A `clarify_sim` object\n#&gt;  - 4 coefficients, 1000 simulated values\n#&gt;  - sampled distribution: multivariate normal\n#&gt;  - original fitting function call:\n#&gt; \n#&gt; glm(formula = CVD ~ Smoke + x.Age + x.Gender, family = binomial(link = \"logit\"), \n#&gt;     data = after_match, weights = after_match$weights)\n\nest &lt;- sim_ame(sim_coefs, var = \"Smoke\", subset = Smoke == 1,\n               contrast = \"rr\" , verbose = F)   # \"diff\" ,sr, ar\n\nest\n#&gt; A `clarify_est` object (from `sim_ame()`)\n#&gt;  - Average adjusted predictions for `Smoke`\n#&gt;  - 1000 simulated values\n#&gt;  - 3 quantities estimated:                    \n#&gt;  E[Y(0)]  0.01111425\n#&gt;  E[Y(1)]  0.55066079\n#&gt;  RR      49.54547289\nsummary(est)\n#&gt;         Estimate    2.5 %   97.5 %\n#&gt; E[Y(0)]  0.01111  0.00722  0.01750\n#&gt; E[Y(1)]  0.55066  0.52059  0.57988\n#&gt; RR      49.54547 31.86784 76.39909\n\n# 绘制 ATT\nplot(est)\n\n\n\n\n\n\n\n\nShow the codeATT_func &lt;- function(fit) {\n  d &lt;- subset(data, Smoke == 1)\n  d$treat &lt;- 1\n  p1 &lt;- mean(predict(fit, newdata = d, type = \"response\"))\n  d$treat &lt;- 0\n  p0 &lt;- mean(predict(fit, newdata = d, type = \"response\"))\n  c(`E[Y(0)]` = p0, `E[Y(1)]` = p1, `RR` = p1 / p0)\n}\n\nsim_est &lt;- sim_apply(sim = sim_coefs, ATT_func )\n\nsim_est\n#&gt; A `clarify_est` object (from `sim_apply()`)\n#&gt;  - 1000 simulated values\n#&gt;  - 3 quantities estimated:                  \n#&gt;  E[Y(0)] 0.5506608\n#&gt;  E[Y(1)] 0.5506608\n#&gt;  RR      1.0000000\n\nsummary(sim_est)\n#&gt;         Estimate 2.5 % 97.5 %\n#&gt; E[Y(0)]    0.551 0.521  0.580\n#&gt; E[Y(1)]    0.551 0.521  0.580\n#&gt; RR         1.000 1.000  1.000\n\n\n\n1.5.2 敏感性分析\n\n1.5.2.1 Rosenbaum 的原始敏感性分析\n常用函数 binarysens 和 psens。前者用于二元结果，后者用于连续或顺序结果。\n\nShow the codelibrary(rbounds)\n\n\n\n1.5.2.2 E 值\n\nShow the codeif(!require(EValue)) install.packages(\"EValue\")\n\nevalue(est = RR(0.8), lo = .7, hi = .9)\n#&gt;             point lower    upper\n#&gt; RR       0.800000   0.7 0.900000\n#&gt; E-values 1.809017    NA 1.462475\n\n\n\n1.5.2.3 倾向得分校准 （PSC）\n\nShow the codemdl1 &lt;- glm(Smoke ~ x.Age,family = binomial, data = data[1:300,])\nPS_raw &lt;- predict(mdl1, newdata = data[1:300,],type = \"response\")\n\nmdl2 &lt;- glm(Smoke ~ x.Age,family = binomial, data = data[301:1000,])\nPS2 &lt;- predict(mdl2, newdata = data[301:1000,],type = \"response\")\n\nmdl3 &lt;- glm(Smoke ~ x.Age + x.Gender,family = binomial, data = data[301:1000,])\nPS3 &lt;- predict(mdl3, newdata = data[301:1000,],type = \"response\")\n\ndata_reg &lt;- data.frame(PS2,PS3)\n\nmdl_calibrated &lt;- lm(PS3 ~ PS2,data = data_reg)\n\nps_calibrated &lt;- predict(mdl_calibrated, x = PS_raw)",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#多分类或连续治疗",
    "href": "PSM.html#多分类或连续治疗",
    "title": "\n1  PSM\n",
    "section": "\n1.6 多分类或连续治疗",
    "text": "1.6 多分类或连续治疗",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "PSM.html#时间依赖性协变量",
    "href": "PSM.html#时间依赖性协变量",
    "title": "\n1  PSM\n",
    "section": "\n1.7 时间依赖性协变量",
    "text": "1.7 时间依赖性协变量",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PSM</span>"
    ]
  },
  {
    "objectID": "stratification.html",
    "href": "stratification.html",
    "title": "\n2  分层（Stratification）\n",
    "section": "",
    "text": "2.1 估计倾向得分（逻辑回归）\nShow the codedata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2)\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n倾向性得分就是模型的拟合值，检查倾向得分的分布，以确保我们有良好的重叠\nShow the codelalonde$lr_ps &lt;- fitted(lr_out)\n\nggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density() +\n    xlab('Propensity Score')",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计倾向得分逻辑回归",
    "href": "stratification.html#估计倾向得分逻辑回归",
    "title": "\n2  分层（Stratification）\n",
    "section": "",
    "text": "2.1.1 分层\n根据倾向分数使用五分位数进行分层\n\nShow the codebreaks5 &lt;- psa::get_strata_breaks(lalonde$lr_ps)\nstr(breaks5)\n#&gt; List of 2\n#&gt;  $ breaks: Named num [1:6] 0.0849 0.3403 0.3594 0.408 0.5112 ...\n#&gt;   ..- attr(*, \"names\")= chr [1:6] \"0%\" \"20%\" \"40%\" \"60%\" ...\n#&gt;  $ labels:'data.frame':  5 obs. of  4 variables:\n#&gt;   ..$ strata: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n#&gt;   ..$ xmin  : num [1:5] 0.0849 0.3403 0.3594 0.408 0.5112\n#&gt;   ..$ xmax  : num [1:5] 0.34 0.359 0.408 0.511 0.83\n#&gt;   ..$ xmid  : num [1:5] 0.213 0.35 0.384 0.46 0.671\n\nlalonde$lr_strata5 &lt;- cut(x = lalonde$lr_ps, \n                          breaks = breaks5$breaks, \n                          include.lowest = TRUE, \n                          labels = breaks5$labels$strata)\ntable(lalonde$treat, lalonde$lr_strata5)\n#&gt;    \n#&gt;      A  B  C  D  E\n#&gt;   0 66 61 51 42 40\n#&gt;   1 23 28 38 47 49\n\n\n\nShow the codeggplot(lalonde, aes(x = lr_ps, color = as.logical(treat))) + \n    geom_density(aes(fill = as.logical(treat)), alpha = 0.2) +\n    geom_vline(xintercept = breaks5$breaks, alpha = 0.5) +\n    geom_text(data = breaks5$labels, \n              aes(x = xmid, y = 0, label = strata),\n              color = 'black', vjust = 1) +\n    xlab('Propensity Score') + ylab('Density') +\n    xlim(c(0, 1))\n\n\n\n\n\n\n\n\nShow the codeggplot() +\n    geom_vline(xintercept = breaks5$breaks) +\n    geom_point(data = lalonde, aes(x = lr_ps, y = log(re78 + 1), color = as.logical(treat)), alpha = 0.5) +\n    geom_text(data = breaks5$labels, aes(x = xmid, y = 0, label = strata), color = 'black', vjust = 1) +\n    xlab('Propensity Score')\n\n\n\n\n\n\n\n\n2.1.2 查看平衡混杂效应\n\nShow the codecovars &lt;- all.vars(lalonde_formu)\ncovars &lt;- lalonde[,covars[-1]]\nPSAgraphics::cv.bal.psa(covariates = covars, \n                        treatment = lalonde$treat,\n                        propensity = lalonde$lr_ps,\n                        strata = lalonde$lr_strata)\n\n\n\n\n\n\n\n\n2.1.2.1 数值变量的协变量平衡图\n\nShow the codePSAgraphics::box.psa(continuous = lalonde$age, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata,\n                     xlab = \"Strata\", \n                     balance = FALSE,\n                     main = 'Covariate: age')\n\n\n\n\n\n\n\n\n2.1.2.2 分类变量的协变量平衡图\n\nShow the codePSAgraphics::cat.psa(categorical = lalonde$nodegr, \n                     treatment = lalonde$treat, \n                     strata = lalonde$lr_strata, \n                     xlab = 'Strata',\n                     balance = FALSE,\n                     main = 'Covariate: nodegr')\n\n\n\n\n\n\n#&gt; $`treatment:stratum.proportions`\n#&gt;   0:A 1:A 0:B   1:B   0:C 1:C   0:D   1:D   0:E   1:E\n#&gt; 0   0   0   0 0.036 0.039   0 0.333 0.383 0.675 0.714\n#&gt; 1   1   1   1 0.964 0.961   1 0.667 0.617 0.325 0.286",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#估计因果效应",
    "href": "stratification.html#估计因果效应",
    "title": "\n2  分层（Stratification）\n",
    "section": "\n2.2 估计因果效应",
    "text": "2.2 估计因果效应\n\nShow the codePSAgraphics::loess.psa(response = log(lalonde$re78 + 1),\n                       treatment = lalonde$treat,\n                       propensity = lalonde$lr_ps)\n\n\n\n\n\n\n#&gt; $ATE\n#&gt; [1] 0.9008386\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.3913399\n#&gt; \n#&gt; $CI95\n#&gt; [1] 0.1181588 1.6835185\n#&gt; \n#&gt; $summary.strata\n#&gt;    counts.0 counts.1  means.0  means.1 diff.means\n#&gt; 1        34       11 6.268705 6.474912  0.2062076\n#&gt; 2        32       12 5.491717 5.659280  0.1675631\n#&gt; 3        31       14 5.467712 5.703584  0.2358722\n#&gt; 4        30       14 5.425593 5.747613  0.3220194\n#&gt; 5        27       18 5.397146 5.831117  0.4339703\n#&gt; 6        24       20 5.302660 6.339721  1.0370619\n#&gt; 7        21       23 5.125331 6.607936  1.4826043\n#&gt; 8        21       24 5.036908 6.594808  1.5578999\n#&gt; 9        22       22 5.182703 6.981383  1.7986801\n#&gt; 10       18       27 6.047529 7.820786  1.7732573\n\npsa::loess_plot(ps = lalonde$lr_ps,\n                outcome = log(lalonde$re78 + 1),\n                treatment = lalonde$treat == 1,\n                outcomeTitle = 'log(re78)',\n                \n                plot.strata = 5,\n                points.treat.alpha = 0.5,\n                points.control.alpha = 0.5,\n                percentPoints.treat = 1,\n                percentPoints.control = 1,\n                se = FALSE, \n                method = 'loess')\n\n\n\n\n\n\n\n\nShow the codePSAgraphics::circ.psa(response = log(lalonde$re78 + 1), \n                      treatment = lalonde$treat == 1, \n                      strata = lalonde$lr_strata5)\n\n\n\n\n\n\n#&gt; $summary.strata\n#&gt;   n.FALSE n.TRUE means.FALSE means.TRUE\n#&gt; A      66     23    6.280406   6.600537\n#&gt; B      61     28    4.409935   5.129193\n#&gt; C      51     38    6.212981   6.455034\n#&gt; D      42     47    4.705981   6.208840\n#&gt; E      40     49    5.783529   7.576461\n#&gt; \n#&gt; $wtd.Mn.FALSE\n#&gt; [1] 5.478567\n#&gt; \n#&gt; $wtd.Mn.TRUE\n#&gt; [1] 6.394013\n#&gt; \n#&gt; $ATE\n#&gt; [1] 0.9154463\n#&gt; \n#&gt; $se.wtd\n#&gt; [1] 0.394155\n#&gt; \n#&gt; $approx.t\n#&gt; [1] 2.322554\n#&gt; \n#&gt; $df\n#&gt; [1] 435\n#&gt; \n#&gt; $CI.95\n#&gt; [1] 0.1407612 1.6901314",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "stratification.html#敏感性分析",
    "href": "stratification.html#敏感性分析",
    "title": "\n2  分层（Stratification）\n",
    "section": "\n2.3 敏感性分析",
    "text": "2.3 敏感性分析\n评估该效果的稳健性\n\n2.3.1 估计倾向得分（分类树）\n\nShow the codelibrary(tree)\ntree_out &lt;- tree::tree(lalonde_formu,\n                       data = lalonde)\n\nplot(tree_out); text(tree_out)\n\n\n\n\n\n\nShow the code\n\nlalonde$tree_ps &lt;- predict(tree_out)\ntable(lalonde$tree_ps, lalonde$treat, useNA = 'ifany')\n#&gt;                    \n#&gt;                       0   1\n#&gt;   0.332             167  83\n#&gt;   0.344827586206897  19  10\n#&gt;   0.351851851851852  35  19\n#&gt;   0.612903225806452  24  38\n#&gt;   0.659090909090909  15  29\n#&gt;   1                   0   6\nlalonde$tree_strata &lt;- predict(tree_out, type = 'where')\ntable(lalonde$tree_strata, lalonde$treat, useNA = 'ifany')\n#&gt;     \n#&gt;        0   1\n#&gt;   3  167  83\n#&gt;   5   15  29\n#&gt;   6   35  19\n#&gt;   9   24  38\n#&gt;   10  19  10\n#&gt;   11   0   6",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>分层（Stratification）</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "\n3  匹配（Matching）\n",
    "section": "",
    "text": "3.1 数据来源\nhttps://hbiostat.org/data/\nhttps://hbiostat.org/data/repo/rhc\nShow the coderhc &lt;- read_csv(\"data/PS/rhc.csv\")\n\nrhc %&gt;% \n    select(age, sex, race, edu, income, ninsclas, cat1,das2d3pc, dnr1, \n           ca, surv2md1, aps1, scoma1, wtkilo1, temp1, meanbp1, resp1,\n           hrt1, pafi1, paco21, ph1, wblc1, hema1, sod1, pot1, crea1,\n           bili1, alb1, resp, card, neuro, gastr, renal, meta, hema,\n           seps, trauma, ortho, cardiohx, chfhx, dementhx, psychhx,\n           chrpulhx, renalhx, liverhx, gibledhx, malighx, immunhx, \n           transhx, amihx, swang1) %&gt;% \n    mutate(\n        across(where(is.character), as.factor),\n        across(ends_with(\"hx\"), as.factor)\n    )-&gt;\n    rhc2\nrhc2 %&gt;% select(where(is.factor)) %&gt;% \n    map(table)\n#&gt; $sex\n#&gt; \n#&gt; Female   Male \n#&gt;   2543   3192 \n#&gt; \n#&gt; $race\n#&gt; \n#&gt; black other white \n#&gt;   920   355  4460 \n#&gt; \n#&gt; $income\n#&gt; \n#&gt;   $11-$25k   $25-$50k     &gt; $50k Under $11k \n#&gt;       1165        893        451       3226 \n#&gt; \n#&gt; $ninsclas\n#&gt; \n#&gt;            Medicaid            Medicare Medicare & Medicaid        No insurance \n#&gt;                 647                1458                 374                 322 \n#&gt;             Private  Private & Medicare \n#&gt;                1698                1236 \n#&gt; \n#&gt; $cat1\n#&gt; \n#&gt;               ARF               CHF         Cirrhosis      Colon Cancer \n#&gt;              2490               456               224                 7 \n#&gt;              Coma              COPD       Lung Cancer MOSF w/Malignancy \n#&gt;               436               457                39               399 \n#&gt;     MOSF w/Sepsis \n#&gt;              1227 \n#&gt; \n#&gt; $dnr1\n#&gt; \n#&gt;   No  Yes \n#&gt; 5081  654 \n#&gt; \n#&gt; $ca\n#&gt; \n#&gt; Metastatic         No        Yes \n#&gt;        384       4379        972 \n#&gt; \n#&gt; $resp\n#&gt; \n#&gt;   No  Yes \n#&gt; 3622 2113 \n#&gt; \n#&gt; $card\n#&gt; \n#&gt;   No  Yes \n#&gt; 3804 1931 \n#&gt; \n#&gt; $neuro\n#&gt; \n#&gt;   No  Yes \n#&gt; 5042  693 \n#&gt; \n#&gt; $gastr\n#&gt; \n#&gt;   No  Yes \n#&gt; 4793  942 \n#&gt; \n#&gt; $renal\n#&gt; \n#&gt;   No  Yes \n#&gt; 5440  295 \n#&gt; \n#&gt; $meta\n#&gt; \n#&gt;   No  Yes \n#&gt; 5470  265 \n#&gt; \n#&gt; $hema\n#&gt; \n#&gt;   No  Yes \n#&gt; 5381  354 \n#&gt; \n#&gt; $seps\n#&gt; \n#&gt;   No  Yes \n#&gt; 4704 1031 \n#&gt; \n#&gt; $trauma\n#&gt; \n#&gt;   No  Yes \n#&gt; 5683   52 \n#&gt; \n#&gt; $ortho\n#&gt; \n#&gt;   No  Yes \n#&gt; 5728    7 \n#&gt; \n#&gt; $cardiohx\n#&gt; \n#&gt;    0    1 \n#&gt; 4722 1013 \n#&gt; \n#&gt; $chfhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4714 1021 \n#&gt; \n#&gt; $dementhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5171  564 \n#&gt; \n#&gt; $psychhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5349  386 \n#&gt; \n#&gt; $chrpulhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4646 1089 \n#&gt; \n#&gt; $renalhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5480  255 \n#&gt; \n#&gt; $liverhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5334  401 \n#&gt; \n#&gt; $gibledhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5550  185 \n#&gt; \n#&gt; $malighx\n#&gt; \n#&gt;    0    1 \n#&gt; 4419 1316 \n#&gt; \n#&gt; $immunhx\n#&gt; \n#&gt;    0    1 \n#&gt; 4192 1543 \n#&gt; \n#&gt; $transhx\n#&gt; \n#&gt;    0    1 \n#&gt; 5073  662 \n#&gt; \n#&gt; $amihx\n#&gt; \n#&gt;    0    1 \n#&gt; 5535  200 \n#&gt; \n#&gt; $swang1\n#&gt; \n#&gt; No RHC    RHC \n#&gt;   3551   2184\n\nrhc2 %&gt;% select(where(is.numeric)) %&gt;% \n    summary()\n#&gt;       age              edu           das2d3pc        surv2md1     \n#&gt;  Min.   : 18.04   Min.   : 0.00   Min.   :11.00   Min.   :0.0000  \n#&gt;  1st Qu.: 50.15   1st Qu.:10.00   1st Qu.:16.06   1st Qu.:0.4709  \n#&gt;  Median : 64.05   Median :12.00   Median :19.75   Median :0.6280  \n#&gt;  Mean   : 61.38   Mean   :11.68   Mean   :20.50   Mean   :0.5925  \n#&gt;  3rd Qu.: 73.93   3rd Qu.:13.00   3rd Qu.:23.43   3rd Qu.:0.7430  \n#&gt;  Max.   :101.85   Max.   :30.00   Max.   :33.00   Max.   :0.9620  \n#&gt;       aps1            scoma1       wtkilo1           temp1      \n#&gt;  Min.   :  3.00   Min.   :  0   Min.   :  0.00   Min.   :27.00  \n#&gt;  1st Qu.: 41.00   1st Qu.:  0   1st Qu.: 56.30   1st Qu.:36.09  \n#&gt;  Median : 54.00   Median :  0   Median : 70.00   Median :38.09  \n#&gt;  Mean   : 54.67   Mean   : 21   Mean   : 67.83   Mean   :37.62  \n#&gt;  3rd Qu.: 67.00   3rd Qu.: 41   3rd Qu.: 83.70   3rd Qu.:39.00  \n#&gt;  Max.   :147.00   Max.   :100   Max.   :244.00   Max.   :43.00  \n#&gt;     meanbp1           resp1             hrt1           pafi1      \n#&gt;  Min.   :  0.00   Min.   :  0.00   Min.   :  0.0   Min.   : 11.6  \n#&gt;  1st Qu.: 50.00   1st Qu.: 14.00   1st Qu.: 97.0   1st Qu.:133.3  \n#&gt;  Median : 63.00   Median : 30.00   Median :124.0   Median :202.5  \n#&gt;  Mean   : 78.52   Mean   : 28.09   Mean   :115.2   Mean   :222.3  \n#&gt;  3rd Qu.:115.00   3rd Qu.: 38.00   3rd Qu.:141.0   3rd Qu.:316.6  \n#&gt;  Max.   :259.00   Max.   :100.00   Max.   :250.0   Max.   :937.5  \n#&gt;      paco21            ph1            wblc1             hema1      \n#&gt;  Min.   :  1.00   Min.   :6.579   Min.   :  0.000   Min.   : 2.00  \n#&gt;  1st Qu.: 31.00   1st Qu.:7.340   1st Qu.:  8.398   1st Qu.:26.10  \n#&gt;  Median : 37.00   Median :7.400   Median : 14.100   Median :30.00  \n#&gt;  Mean   : 38.75   Mean   :7.388   Mean   : 15.645   Mean   :31.87  \n#&gt;  3rd Qu.: 42.00   3rd Qu.:7.460   3rd Qu.: 20.049   3rd Qu.:36.30  \n#&gt;  Max.   :156.00   Max.   :7.770   Max.   :192.000   Max.   :66.19  \n#&gt;       sod1            pot1            crea1              bili1         \n#&gt;  Min.   :101.0   Min.   : 1.100   Min.   : 0.09999   Min.   : 0.09999  \n#&gt;  1st Qu.:132.0   1st Qu.: 3.400   1st Qu.: 1.00000   1st Qu.: 0.79993  \n#&gt;  Median :136.0   Median : 3.800   Median : 1.50000   Median : 1.00977  \n#&gt;  Mean   :136.8   Mean   : 4.067   Mean   : 2.13302   Mean   : 2.26707  \n#&gt;  3rd Qu.:142.0   3rd Qu.: 4.600   3rd Qu.: 2.39990   3rd Qu.: 1.39990  \n#&gt;  Max.   :178.0   Max.   :11.898   Max.   :25.09766   Max.   :58.19531  \n#&gt;       alb1       \n#&gt;  Min.   : 0.300  \n#&gt;  1st Qu.: 2.600  \n#&gt;  Median : 3.500  \n#&gt;  Mean   : 3.093  \n#&gt;  3rd Qu.: 3.500  \n#&gt;  Max.   :29.000\n\n\n\nlibrary(tableone)\n\nCreateTableOne(strata = \"swang1\",\n               data = rhc2\n                ) %&gt;% print(.,showAllLevels = T,smd = T, addOverall = T)\n#&gt;                       Stratified by swang1\n#&gt;                        level               No RHC          RHC            \n#&gt;   n                                          3551            2184         \n#&gt;   age (mean (SD))                           61.76 (17.29)   60.75 (15.63) \n#&gt;   sex (%)              Female                1637 ( 46.1)     906 ( 41.5) \n#&gt;                        Male                  1914 ( 53.9)    1278 ( 58.5) \n#&gt;   race (%)             black                  585 ( 16.5)     335 ( 15.3) \n#&gt;                        other                  213 (  6.0)     142 (  6.5) \n#&gt;                        white                 2753 ( 77.5)    1707 ( 78.2) \n#&gt;   edu (mean (SD))                           11.57 (3.13)    11.86 (3.16)  \n#&gt;   income (%)           $11-$25k               713 ( 20.1)     452 ( 20.7) \n#&gt;                        $25-$50k               500 ( 14.1)     393 ( 18.0) \n#&gt;                        &gt; $50k                 257 (  7.2)     194 (  8.9) \n#&gt;                        Under $11k            2081 ( 58.6)    1145 ( 52.4) \n#&gt;   ninsclas (%)         Medicaid               454 ( 12.8)     193 (  8.8) \n#&gt;                        Medicare               947 ( 26.7)     511 ( 23.4) \n#&gt;                        Medicare & Medicaid    251 (  7.1)     123 (  5.6) \n#&gt;                        No insurance           186 (  5.2)     136 (  6.2) \n#&gt;                        Private                967 ( 27.2)     731 ( 33.5) \n#&gt;                        Private & Medicare     746 ( 21.0)     490 ( 22.4) \n#&gt;   cat1 (%)             ARF                   1581 ( 44.5)     909 ( 41.6) \n#&gt;                        CHF                    247 (  7.0)     209 (  9.6) \n#&gt;                        Cirrhosis              175 (  4.9)      49 (  2.2) \n#&gt;                        Colon Cancer             6 (  0.2)       1 (  0.0) \n#&gt;                        Coma                   341 (  9.6)      95 (  4.3) \n#&gt;                        COPD                   399 ( 11.2)      58 (  2.7) \n#&gt;                        Lung Cancer             34 (  1.0)       5 (  0.2) \n#&gt;                        MOSF w/Malignancy      241 (  6.8)     158 (  7.2) \n#&gt;                        MOSF w/Sepsis          527 ( 14.8)     700 ( 32.1) \n#&gt;   das2d3pc (mean (SD))                      20.37 (5.48)    20.70 (5.03)  \n#&gt;   dnr1 (%)             No                    3052 ( 85.9)    2029 ( 92.9) \n#&gt;                        Yes                    499 ( 14.1)     155 (  7.1) \n#&gt;   ca (%)               Metastatic             261 (  7.4)     123 (  5.6) \n#&gt;                        No                    2652 ( 74.7)    1727 ( 79.1) \n#&gt;                        Yes                    638 ( 18.0)     334 ( 15.3) \n#&gt;   surv2md1 (mean (SD))                       0.61 (0.19)     0.57 (0.20)  \n#&gt;   aps1 (mean (SD))                          50.93 (18.81)   60.74 (20.27) \n#&gt;   scoma1 (mean (SD))                        22.25 (31.37)   18.97 (28.26) \n#&gt;   wtkilo1 (mean (SD))                       65.04 (29.50)   72.36 (27.73) \n#&gt;   temp1 (mean (SD))                         37.63 (1.74)    37.59 (1.83)  \n#&gt;   meanbp1 (mean (SD))                       84.87 (38.87)   68.20 (34.24) \n#&gt;   resp1 (mean (SD))                         28.98 (13.95)   26.65 (14.17) \n#&gt;   hrt1 (mean (SD))                         112.87 (40.94)  118.93 (41.47) \n#&gt;   pafi1 (mean (SD))                        240.63 (116.66) 192.43 (105.54)\n#&gt;   paco21 (mean (SD))                        39.95 (14.24)   36.79 (10.97) \n#&gt;   ph1 (mean (SD))                            7.39 (0.11)     7.38 (0.11)  \n#&gt;   wblc1 (mean (SD))                         15.26 (11.41)   16.27 (12.55) \n#&gt;   hema1 (mean (SD))                         32.70 (8.79)    30.51 (7.42)  \n#&gt;   sod1 (mean (SD))                         137.04 (7.68)   136.33 (7.60)  \n#&gt;   pot1 (mean (SD))                           4.08 (1.04)     4.05 (1.01)  \n#&gt;   crea1 (mean (SD))                          1.92 (2.03)     2.47 (2.05)  \n#&gt;   bili1 (mean (SD))                          2.00 (4.43)     2.71 (5.33)  \n#&gt;   alb1 (mean (SD))                           3.16 (0.67)     2.98 (0.93)  \n#&gt;   resp (%)             No                    2070 ( 58.3)    1552 ( 71.1) \n#&gt;                        Yes                   1481 ( 41.7)     632 ( 28.9) \n#&gt;   card (%)             No                    2544 ( 71.6)    1260 ( 57.7) \n#&gt;                        Yes                   1007 ( 28.4)     924 ( 42.3) \n#&gt;   neuro (%)            No                    2976 ( 83.8)    2066 ( 94.6) \n#&gt;                        Yes                    575 ( 16.2)     118 (  5.4) \n#&gt;   gastr (%)            No                    3029 ( 85.3)    1764 ( 80.8) \n#&gt;                        Yes                    522 ( 14.7)     420 ( 19.2) \n#&gt;   renal (%)            No                    3404 ( 95.9)    2036 ( 93.2) \n#&gt;                        Yes                    147 (  4.1)     148 (  6.8) \n#&gt;   meta (%)             No                    3379 ( 95.2)    2091 ( 95.7) \n#&gt;                        Yes                    172 (  4.8)      93 (  4.3) \n#&gt;   hema (%)             No                    3312 ( 93.3)    2069 ( 94.7) \n#&gt;                        Yes                    239 (  6.7)     115 (  5.3) \n#&gt;   seps (%)             No                    3036 ( 85.5)    1668 ( 76.4) \n#&gt;                        Yes                    515 ( 14.5)     516 ( 23.6) \n#&gt;   trauma (%)           No                    3533 ( 99.5)    2150 ( 98.4) \n#&gt;                        Yes                     18 (  0.5)      34 (  1.6) \n#&gt;   ortho (%)            No                    3548 ( 99.9)    2180 ( 99.8) \n#&gt;                        Yes                      3 (  0.1)       4 (  0.2) \n#&gt;   cardiohx (%)         0                     2984 ( 84.0)    1738 ( 79.6) \n#&gt;                        1                      567 ( 16.0)     446 ( 20.4) \n#&gt;   chfhx (%)            0                     2955 ( 83.2)    1759 ( 80.5) \n#&gt;                        1                      596 ( 16.8)     425 ( 19.5) \n#&gt;   dementhx (%)         0                     3138 ( 88.4)    2033 ( 93.1) \n#&gt;                        1                      413 ( 11.6)     151 (  6.9) \n#&gt;   psychhx (%)          0                     3265 ( 91.9)    2084 ( 95.4) \n#&gt;                        1                      286 (  8.1)     100 (  4.6) \n#&gt;   chrpulhx (%)         0                     2777 ( 78.2)    1869 ( 85.6) \n#&gt;                        1                      774 ( 21.8)     315 ( 14.4) \n#&gt;   renalhx (%)          0                     3402 ( 95.8)    2078 ( 95.1) \n#&gt;                        1                      149 (  4.2)     106 (  4.9) \n#&gt;   liverhx (%)          0                     3286 ( 92.5)    2048 ( 93.8) \n#&gt;                        1                      265 (  7.5)     136 (  6.2) \n#&gt;   gibledhx (%)         0                     3420 ( 96.3)    2130 ( 97.5) \n#&gt;                        1                      131 (  3.7)      54 (  2.5) \n#&gt;   malighx (%)          0                     2679 ( 75.4)    1740 ( 79.7) \n#&gt;                        1                      872 ( 24.6)     444 ( 20.3) \n#&gt;   immunhx (%)          0                     2644 ( 74.5)    1548 ( 70.9) \n#&gt;                        1                      907 ( 25.5)     636 ( 29.1) \n#&gt;   transhx (%)          0                     3216 ( 90.6)    1857 ( 85.0) \n#&gt;                        1                      335 (  9.4)     327 ( 15.0) \n#&gt;   amihx (%)            0                     3446 ( 97.0)    2089 ( 95.7) \n#&gt;                        1                      105 (  3.0)      95 (  4.3) \n#&gt;   swang1 (%)           No RHC                3551 (100.0)       0 (  0.0) \n#&gt;                        RHC                      0 (  0.0)    2184 (100.0) \n#&gt;                       Stratified by swang1\n#&gt;                        p      test SMD   \n#&gt;   n                                      \n#&gt;   age (mean (SD))       0.026       0.061\n#&gt;   sex (%)               0.001       0.093\n#&gt;                                          \n#&gt;   race (%)              0.425       0.036\n#&gt;                                          \n#&gt;                                          \n#&gt;   edu (mean (SD))       0.001       0.091\n#&gt;   income (%)           &lt;0.001       0.142\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   ninsclas (%)         &lt;0.001       0.194\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   cat1 (%)             &lt;0.001       0.583\n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;                                          \n#&gt;   das2d3pc (mean (SD))  0.023       0.063\n#&gt;   dnr1 (%)             &lt;0.001       0.228\n#&gt;                                          \n#&gt;   ca (%)                0.001       0.107\n#&gt;                                          \n#&gt;                                          \n#&gt;   surv2md1 (mean (SD)) &lt;0.001       0.198\n#&gt;   aps1 (mean (SD))     &lt;0.001       0.501\n#&gt;   scoma1 (mean (SD))   &lt;0.001       0.110\n#&gt;   wtkilo1 (mean (SD))  &lt;0.001       0.256\n#&gt;   temp1 (mean (SD))     0.429       0.021\n#&gt;   meanbp1 (mean (SD))  &lt;0.001       0.455\n#&gt;   resp1 (mean (SD))    &lt;0.001       0.165\n#&gt;   hrt1 (mean (SD))     &lt;0.001       0.147\n#&gt;   pafi1 (mean (SD))    &lt;0.001       0.433\n#&gt;   paco21 (mean (SD))   &lt;0.001       0.249\n#&gt;   ph1 (mean (SD))      &lt;0.001       0.120\n#&gt;   wblc1 (mean (SD))     0.002       0.084\n#&gt;   hema1 (mean (SD))    &lt;0.001       0.269\n#&gt;   sod1 (mean (SD))      0.001       0.092\n#&gt;   pot1 (mean (SD))      0.321       0.027\n#&gt;   crea1 (mean (SD))    &lt;0.001       0.270\n#&gt;   bili1 (mean (SD))    &lt;0.001       0.145\n#&gt;   alb1 (mean (SD))     &lt;0.001       0.230\n#&gt;   resp (%)             &lt;0.001       0.270\n#&gt;                                          \n#&gt;   card (%)             &lt;0.001       0.295\n#&gt;                                          \n#&gt;   neuro (%)            &lt;0.001       0.353\n#&gt;                                          \n#&gt;   gastr (%)            &lt;0.001       0.121\n#&gt;                                          \n#&gt;   renal (%)            &lt;0.001       0.116\n#&gt;                                          \n#&gt;   meta (%)              0.337       0.028\n#&gt;                                          \n#&gt;   hema (%)              0.029       0.062\n#&gt;                                          \n#&gt;   seps (%)             &lt;0.001       0.234\n#&gt;                                          \n#&gt;   trauma (%)           &lt;0.001       0.104\n#&gt;                                          \n#&gt;   ortho (%)             0.516       0.027\n#&gt;                                          \n#&gt;   cardiohx (%)         &lt;0.001       0.116\n#&gt;                                          \n#&gt;   chfhx (%)             0.011       0.070\n#&gt;                                          \n#&gt;   dementhx (%)         &lt;0.001       0.163\n#&gt;                                          \n#&gt;   psychhx (%)          &lt;0.001       0.143\n#&gt;                                          \n#&gt;   chrpulhx (%)         &lt;0.001       0.192\n#&gt;                                          \n#&gt;   renalhx (%)           0.268       0.032\n#&gt;                                          \n#&gt;   liverhx (%)           0.084       0.049\n#&gt;                                          \n#&gt;   gibledhx (%)          0.014       0.070\n#&gt;                                          \n#&gt;   malighx (%)          &lt;0.001       0.101\n#&gt;                                          \n#&gt;   immunhx (%)           0.003       0.080\n#&gt;                                          \n#&gt;   transhx (%)          &lt;0.001       0.170\n#&gt;                                          \n#&gt;   amihx (%)             0.007       0.074\n#&gt;                                          \n#&gt;   swang1 (%)           &lt;0.001         NaN\n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#数据来源",
    "href": "matching.html#数据来源",
    "title": "\n3  匹配（Matching）\n",
    "section": "",
    "text": "Variable name\nVariable Definition\n\n\nAge\nAge\n\n\nSex\nSex\n\n\nRace\nRace\n\n\nEdu\nYears of education\n\n\nIncome\nIncome\n\n\nNinsclas\nMedical insurance\n\n\nCat1\nPrimary disease category\n\n\nCat2\nSecondary disease category\n\n\nCategories of admission diagnosis:\n \n\n\nResp\nRespiratory Diagnosis\n\n\nCard\nCardiovascular Diagnosis\n\n\nNeuro\nNeurological Diagnosis\n\n\nGastr\nGastrointestinal Diagnosis\n\n\nRenal\nRenal Diagnosis\n\n\nMeta\nMetabolic Diagnosis\n\n\nHema\nHematologic Diagnosis\n\n\nSeps\nSepsis Diagnosis\n\n\nTrauma\nTrauma Diagnosis\n\n\nOrtho\nOrthopedic Diagnosis\n\n\n \n \n\n\nAdld3p\nADL\n\n\nDas2d3pc\nDASI ( Duke Activity Status Index)\n\n\nDnr1\nDNR status on day1\n\n\nCa\nCancer\n\n\nSurv2md1\nSupport model estimate of the prob. of surviving 2 months\n\n\nAps1\nAPACHE score\n\n\nScoma1\nGlasgow Coma Score\n\n\nWtkilo1\nWeight\n\n\nTemp1\nTemperature\n\n\nMeanbp1\nMean blood pressure\n\n\nResp1\nRespiratory rate\n\n\nHrt1\nHeart rate\n\n\nPafi1\nPaO2/FIO2 ratio\n\n\nPaco21\nPaCo2\n\n\nPh1\nPH\n\n\nWblc1\nWBC\n\n\nHema1\nHematocrit\n\n\nSod1\nSodium\n\n\nPot1\nPotassium\n\n\nCrea1\nCreatinine\n\n\nBili1\nBilirubin\n\n\nAlb1\nAlbumin\n\n\nUrin1\nUrine output\n\n\nCategories of comorbidities illness:\n \n\n\nCardiohx\nAcute MI, Peripheral Vascular Disease, Severe Cardiovascular Symptoms (NYHA-Class III), Very Severe Cardiovascular Symptoms (NYHA-Class IV)\n\n\nChfhx\nCongestive Heart Failure\n\n\nDementhx\nDementia, Stroke or Cerebral Infarct, Parkinson�s Disease\n\n\nPsychhx\nPsychiatric History, Active Psychosis or Severe Depression\n\n\nChrpulhx\nChronic Pulmonary Disease, Severe Pulmonary Disease, Very Severe Pulmonary Disease\n\n\nRenalhx\nChronic Renal Disease, Chronic Hemodialysis or Peritoneal Dialysis\n\n\nLiverhx\nCirrhosis, Hepatic Failure\n\n\nGibledhx\nUpper GI Bleeding\n\n\nMalighx\nSolid Tumor, Metastatic Disease, Chronic Leukemia/Myeloma, Acute Leukemia, Lymphoma\n\n\nImmunhx\nImmunosupperssion, Organ Transplant, HIV Positivity, Diabetes Mellitus Without End Organ Damage, Diabetes Mellitus With End Organ Damage, Connective Tissue Disease\n\n\nTranshx\nTransfer (&gt; 24 Hours) from Another Hospital\n\n\nAmihx\nDefinite Myocardial Infarction\n\n\n \n \n\n\nSwang1\nRight Heart Catheterization (rhc2)\n\n\nSadmdte\nStudy Admission Date\n\n\nDthdte\nDate of Death\n\n\nLstctdte\nDate of Last Contact\n\n\nDschdte\nHospital Discharge Date\n\n\nDeath\nDeath at any time up to 180 Days\n\n\nPtid\nPatient ID",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#估计倾向得分",
    "href": "matching.html#估计倾向得分",
    "title": "\n3  匹配（Matching）\n",
    "section": "\n3.2 估计倾向得分",
    "text": "3.2 估计倾向得分\n\nShow the code\nlibrary(tidymodels)\nrhc2_formula &lt;- swang1 ~ .\n\n\n\nlogit_ps &lt;- logistic_reg() %&gt;%\n    fit(rhc2_formula, data = rhc2)\n\nsummary(logit_ps$fit)\n#&gt; \n#&gt; Call:\n#&gt; stats::glm(formula = swang1 ~ ., family = stats::binomial, data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)                 17.2203728  3.1137929   5.530 3.20e-08 ***\n#&gt; age                         -0.0043737  0.0028619  -1.528 0.126457    \n#&gt; sexMale                      0.0478361  0.0679017   0.704 0.481128    \n#&gt; raceother                    0.0238498  0.1519260   0.157 0.875258    \n#&gt; racewhite                   -0.0480662  0.0939149  -0.512 0.608787    \n#&gt; edu                          0.0261939  0.0116913   2.240 0.025061 *  \n#&gt; income$25-$50k               0.0888363  0.1094906   0.811 0.417159    \n#&gt; income&gt; $50k                 0.0312483  0.1382814   0.226 0.821220    \n#&gt; incomeUnder $11k             0.0548697  0.0868242   0.632 0.527411    \n#&gt; ninsclasMedicare             0.2328987  0.1351961   1.723 0.084948 .  \n#&gt; ninsclasMedicare & Medicaid  0.4012458  0.1691375   2.372 0.017677 *  \n#&gt; ninsclasNo insurance         0.5264711  0.1673868   3.145 0.001660 ** \n#&gt; ninsclasPrivate              0.4138771  0.1247856   3.317 0.000911 ***\n#&gt; ninsclasPrivate & Medicare   0.3490696  0.1391972   2.508 0.012151 *  \n#&gt; cat1CHF                      0.7833692  0.1596299   4.907 9.23e-07 ***\n#&gt; cat1Cirrhosis               -1.1607975  0.2378358  -4.881 1.06e-06 ***\n#&gt; cat1Colon Cancer            -0.0864465  1.1193521  -0.077 0.938441    \n#&gt; cat1Coma                    -0.5829321  0.1819159  -3.204 0.001353 ** \n#&gt; cat1COPD                    -0.4719080  0.1901740  -2.481 0.013085 *  \n#&gt; cat1Lung Cancer             -0.4138852  0.5445513  -0.760 0.447226    \n#&gt; cat1MOSF w/Malignancy        0.0143100  0.1614131   0.089 0.929356    \n#&gt; cat1MOSF w/Sepsis            0.5339948  0.0910519   5.865 4.50e-09 ***\n#&gt; das2d3pc                    -0.0020607  0.0066432  -0.310 0.756416    \n#&gt; dnr1Yes                     -0.6777513  0.1166464  -5.810 6.24e-09 ***\n#&gt; caNo                         1.0485967  0.4350633   2.410 0.015943 *  \n#&gt; caYes                        0.2805522  0.1619387   1.732 0.083192 .  \n#&gt; surv2md1                    -1.8855344  0.3535424  -5.333 9.65e-08 ***\n#&gt; aps1                         0.0037687  0.0029458   1.279 0.200771    \n#&gt; scoma1                      -0.0041620  0.0016024  -2.597 0.009396 ** \n#&gt; wtkilo1                      0.0063327  0.0012171   5.203 1.96e-07 ***\n#&gt; temp1                       -0.0284681  0.0197651  -1.440 0.149776    \n#&gt; meanbp1                     -0.0063608  0.0010216  -6.226 4.78e-10 ***\n#&gt; resp1                       -0.0207690  0.0025956  -8.002 1.23e-15 ***\n#&gt; hrt1                         0.0054615  0.0008942   6.108 1.01e-09 ***\n#&gt; pafi1                       -0.0047235  0.0003463 -13.639  &lt; 2e-16 ***\n#&gt; paco21                      -0.0261850  0.0036694  -7.136 9.60e-13 ***\n#&gt; ph1                         -1.6756614  0.3847432  -4.355 1.33e-05 ***\n#&gt; wblc1                        0.0001465  0.0027568   0.053 0.957609    \n#&gt; hema1                       -0.0115223  0.0047296  -2.436 0.014841 *  \n#&gt; sod1                        -0.0108807  0.0043040  -2.528 0.011470 *  \n#&gt; pot1                        -0.1720083  0.0341922  -5.031 4.89e-07 ***\n#&gt; crea1                        0.0523499  0.0218175   2.399 0.016420 *  \n#&gt; bili1                        0.0072293  0.0074332   0.973 0.330766    \n#&gt; alb1                        -0.0964314  0.0481135  -2.004 0.045044 *  \n#&gt; respYes                     -0.2725098  0.0827259  -3.294 0.000987 ***\n#&gt; cardYes                      0.5575983  0.0856700   6.509 7.58e-11 ***\n#&gt; neuroYes                    -0.4873660  0.1343763  -3.627 0.000287 ***\n#&gt; gastrYes                     0.3505067  0.1054000   3.325 0.000883 ***\n#&gt; renalYes                     0.3004368  0.1490678   2.015 0.043859 *  \n#&gt; metaYes                     -0.1129081  0.1554971  -0.726 0.467771    \n#&gt; hemaYes                     -0.5131993  0.1470678  -3.490 0.000484 ***\n#&gt; sepsYes                      0.2844857  0.0919399   3.094 0.001973 ** \n#&gt; traumaYes                    1.2560843  0.3346498   3.753 0.000174 ***\n#&gt; orthoYes                     1.1814997  0.9691723   1.219 0.222813    \n#&gt; cardiohx1                    0.0482934  0.0953604   0.506 0.612554    \n#&gt; chfhx1                       0.0936948  0.1042890   0.898 0.368964    \n#&gt; dementhx1                   -0.4121592  0.1213400  -3.397 0.000682 ***\n#&gt; psychhx1                    -0.3913426  0.1382534  -2.831 0.004646 ** \n#&gt; chrpulhx1                    0.0122390  0.1007226   0.122 0.903286    \n#&gt; renalhx1                    -0.3352647  0.1814102  -1.848 0.064588 .  \n#&gt; liverhx1                    -0.0410152  0.1877313  -0.218 0.827057    \n#&gt; gibledhx1                   -0.1856252  0.2283797  -0.813 0.416337    \n#&gt; malighx1                     0.2298479  0.3846516   0.598 0.550141    \n#&gt; immunhx1                     0.0454368  0.0742516   0.612 0.540584    \n#&gt; transhx1                     0.4716832  0.0994237   4.744 2.09e-06 ***\n#&gt; amihx1                       0.1317831  0.1749886   0.753 0.451392    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 7621.4  on 5734  degrees of freedom\n#&gt; Residual deviance: 5993.2  on 5669  degrees of freedom\n#&gt; AIC: 6125.2\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\nrhc2$PS &lt;- fitted(logit_ps$fit)\n\npredict(logit_ps, new_data = rhc2, type = \"prob\") %&gt;% head()\n\n\n\n\n.pred_No RHC\n.pred_RHC\n\n\n\n0.6489847\n0.3510153\n\n\n0.3308540\n0.6691460\n\n\n0.3664559\n0.6335441\n\n\n0.6310644\n0.3689356\n\n\n0.5543195\n0.4456805\n\n\n0.9447431\n0.0552569",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#匹配方法",
    "href": "matching.html#匹配方法",
    "title": "\n3  匹配（Matching）\n",
    "section": "\n3.3 匹配方法",
    "text": "3.3 匹配方法\n\n3.3.1 Matching\n\n\nShow the codelibrary(Matching)\ndata(lalonde, package='Matching')\nglimpse(lalonde)\n#&gt; Rows: 445\n#&gt; Columns: 12\n#&gt; $ age     &lt;int&gt; 37, 22, 30, 27, 33, 22, 23, 32, 22, 33, 19, 21, 18, 27, 17, 19…\n#&gt; $ educ    &lt;int&gt; 11, 9, 12, 11, 8, 9, 12, 11, 16, 12, 9, 13, 8, 10, 7, 10, 13, …\n#&gt; $ black   &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ hisp    &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ married &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ nodegr  &lt;int&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,…\n#&gt; $ re74    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re75    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ re78    &lt;dbl&gt; 9930.05, 3595.89, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 84…\n#&gt; $ u74     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ u75     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ treat   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nlalonde_formu &lt;- treat ~ age + I(age^2) + educ + I(educ^2) + black +\n    hisp + married + nodegr + re74  + I(re74^2) + re75 + I(re75^2) + u74 + u75\nlr_out &lt;- glm(formula = lalonde_formu,\n              data = lalonde,\n              family = binomial(link = 'logit'))\n\nsummary(lr_out)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = lalonde_formu, family = binomial(link = \"logit\"), \n#&gt;     data = lalonde)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept)  4.269e+00  2.173e+00   1.965   0.0494 *\n#&gt; age          2.143e-02  9.037e-02   0.237   0.8126  \n#&gt; I(age^2)    -3.448e-04  1.484e-03  -0.232   0.8163  \n#&gt; educ        -8.713e-01  4.150e-01  -2.099   0.0358 *\n#&gt; I(educ^2)    4.499e-02  2.330e-02   1.931   0.0535 .\n#&gt; black       -2.613e-01  3.708e-01  -0.705   0.4809  \n#&gt; hisp        -8.974e-01  5.184e-01  -1.731   0.0835 .\n#&gt; married      1.829e-01  2.831e-01   0.646   0.5183  \n#&gt; nodegr      -4.285e-01  3.930e-01  -1.090   0.2756  \n#&gt; re74        -2.168e-05  7.739e-05  -0.280   0.7793  \n#&gt; I(re74^2)   -8.553e-10  2.424e-09  -0.353   0.7242  \n#&gt; re75         6.577e-05  1.025e-04   0.642   0.5210  \n#&gt; I(re75^2)   -1.968e-09  5.042e-09  -0.390   0.6963  \n#&gt; u74         -8.315e-02  4.521e-01  -0.184   0.8541  \n#&gt; u75         -3.060e-01  3.591e-01  -0.852   0.3942  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 604.20  on 444  degrees of freedom\n#&gt; Residual deviance: 580.02  on 430  degrees of freedom\n#&gt; AIC: 610.02\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\nlalonde$lr_ps &lt;- fitted(lr_out)\n\n\n\nShow the codelalonde_match &lt;- Match(\n    Y = lalonde$re78,\n    Tr = lalonde$treat,\n    X = lalonde$lr_ps,\n    M = 1,\n    caliper = 0.1,\n    replace = TRUE,\n    estimand = 'ATE'\n)\n\nsummary(lalonde_match)\n#&gt; \n#&gt; Estimate...  2053.1 \n#&gt; AI SE......  803.05 \n#&gt; T-stat.....  2.5566 \n#&gt; p.val......  0.010569 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  433 \n#&gt; Matched number of observations  (unweighted).  744 \n#&gt; \n#&gt; Caliper (SDs)........................................   0.1 \n#&gt; Number of obs dropped by 'exact' or 'caliper'  12\n\nlalonde_match_df &lt;- data.frame(\n    treated.ps = lalonde[lalonde_match$index.treated, ]$lr_ps,\n    control.ps = lalonde[lalonde_match$index.control, ]$lr_ps,\n    treated.y = 1,\n    control.y = 0\n)\nlalonde_match_df &lt;- lalonde_match_df[order(lalonde_match_df$control.ps), ]\n\n\nrows &lt;- (1:nrow(lalonde_match_df) - 1) %% floor(nrow(lalonde_match_df) / 5) == 0\n\nggplot(lalonde, aes(x = lr_ps, y = treat)) +\n    geom_point(alpha = 0.5) +\n    geom_smooth(\n        method = glm,\n        formula = y ~ x,\n        method.args = list(family = binomial(link = 'logit')),\n        se = FALSE\n    ) +\n    xlim(c(0, 1)) +\n    xlab('Propensity Score') + ylab('Treatment') +\n    geom_segment(\n        data = lalonde_match_df,\n        aes(\n            x = treated.ps,\n            xend = control.ps,\n            y = treated.y,\n            yend = control.y\n        ),\n        color = 'purple',\n        alpha = 0.1\n    )\n\n\n\n\n\n\n\n匹配后，治疗组和对照组应具有非常相似的特征。可以使用简单的回归模型来估计治疗对结果的影响。\n\n3.3.2 一对一匹配ATT\nEstimating the treatment effect on the treated (default is ATT)\n\nShow the coderr_att &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand='ATT')\nsummary(rr_att) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\nrr_att_mb &lt;- psa::MatchBalance(\n    df = lalonde,\n    formu = lalonde_formu,\n    formu.Y = update.formula(lalonde_formu, re78 ~ .),\n    index.treated = rr_att$index.treated,\n    index.control = rr_att$index.control,\n    tolerance = 0.25,\n    M = 1,\n    estimand = 'ATT')\nplot(rr_att_mb)\n\n\n\n\n\n\nShow the codesummary(rr_att_mb)\n#&gt; Sample sizes and number of matches:\n#&gt;    Group   n n.matched n.percent.matched\n#&gt;  Treated 185       185         1.0000000\n#&gt;  Control 260       173         0.6653846\n#&gt;    Total 445       358         0.8044944\n#&gt; \n#&gt; Covariate importance and t-tests for matched pairs:\n#&gt;           Import.Treat Import.Y Import.Total std.estimate       t p.value\n#&gt; I(educ^2)        1.931   1.5228        3.453     -0.04903 -0.8916  0.3732\n#&gt; educ             2.099   1.2121        3.311     -0.05483 -0.9577  0.3389\n#&gt; black            0.705   1.8424        2.547     -0.02326 -0.5383  0.5907\n#&gt; I(re74^2)        0.353   1.6415        1.994      0.07581  2.0955  0.0369\n#&gt; u75              0.852   0.9435        1.796     -0.06655 -1.8144  0.0705\n#&gt; hisp             1.731   0.0404        1.771      0.02042  0.8161  0.4150\n#&gt; nodegr           1.090   0.5011        1.591      0.03496  1.0914  0.2759\n#&gt; re74             0.280   1.1019        1.382      0.07979  1.7483  0.0813\n#&gt; re75             0.642   0.5903        1.232      0.06147  1.3171  0.1887\n#&gt; age              0.237   0.6729        0.910      0.00896  0.1374  0.8908\n#&gt; married          0.646   0.1406        0.787      0.04627  1.0000  0.3180\n#&gt; I(re75^2)        0.390   0.3817        0.772      0.05125  1.0364  0.3007\n#&gt; I(age^2)         0.232   0.5096        0.742      0.00297  0.0438  0.9651\n#&gt; u74              0.184   0.0702        0.254      0.03913  0.7495  0.4541\n#&gt;             ci.min  ci.max PercentMatched\n#&gt; I(educ^2) -0.15719 0.05913           60.4\n#&gt; educ      -0.16744 0.05778           60.1\n#&gt; black     -0.10826 0.06173           91.0\n#&gt; I(re74^2)  0.00465 0.14696           86.7\n#&gt; u75       -0.13870 0.00559           89.3\n#&gt; hisp      -0.02879 0.06963           98.3\n#&gt; nodegr    -0.02804 0.09797           93.9\n#&gt; re74      -0.00998 0.16956           77.2\n#&gt; re75      -0.03032 0.15326           78.0\n#&gt; age       -0.11922 0.13713           44.8\n#&gt; married   -0.04474 0.13728           89.6\n#&gt; I(re75^2) -0.04602 0.14852           88.7\n#&gt; I(age^2)  -0.13062 0.13656           49.7\n#&gt; u74       -0.06356 0.14183           81.5\n\n\n\n3.3.3 一对一匹配ATE\naverage treatment effect\n\nShow the coderr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                estimand = 'ATE')\nsummary(rr.ate)\n#&gt; \n#&gt; Estimate...  2013.3 \n#&gt; AI SE......  817.76 \n#&gt; T-stat.....  2.4619 \n#&gt; p.val......  0.013819 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  756\n\n\n\n3.3.4 一对多匹配 （ATT）\n\nShow the coderr2 &lt;- Match(Y = lalonde$re78,      \n             Tr = lalonde$treat, \n             X = lalonde$lr_ps,\n             M = 1, \n             ties = TRUE, \n             replace = TRUE,\n             estimand = 'ATT')\nsummary(rr2) # The default estimate is ATT here\n#&gt; \n#&gt; Estimate...  2153.3 \n#&gt; AI SE......  825.4 \n#&gt; T-stat.....  2.6088 \n#&gt; p.val......  0.0090858 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  346\n\n\n\n3.3.5 MachIt\n\n\nShow the codeMatchIt::matchit(method = \"nearest\")\nMatchIt::matchit(method = 'optimal')\nMatchIt::matchit(method = 'full')\nMatchIt::matchit(method = 'quick')\nMatchIt::matchit(method = 'genetic')\nMatchIt::matchit(method = 'exact')\nMatchIt::matchit(method = 'subclass')\n\n\n\nShow the codematchit.out &lt;- MatchIt::matchit(lalonde_formu, data = lalonde )\nsummary(matchit.out)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = lalonde_formu, data = lalonde)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.3936          0.4533     1.2101    0.1340\n#&gt; age             25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; I(age^2)       717.3946      677.3154          0.0929     1.0115    0.0254\n#&gt; educ            10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; I(educ^2)      111.0595      104.3731          0.1701     1.6625    0.0287\n#&gt; black            0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp             0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married          0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr           0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74          2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; I(re74^2) 28141433.9907 36667413.1577         -0.0747     0.5038    0.0192\n#&gt; re75          1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt; I(re75^2) 12654752.6909 11196530.0057          0.0260     1.4609    0.0508\n#&gt; u74              0.7081        0.7500         -0.0921          .    0.0419\n#&gt; u75              0.6000        0.6846         -0.1727          .    0.0846\n#&gt;           eCDF Max\n#&gt; distance    0.2244\n#&gt; age         0.0652\n#&gt; I(age^2)    0.0652\n#&gt; educ        0.1265\n#&gt; I(educ^2)   0.1265\n#&gt; black       0.0163\n#&gt; hisp        0.0482\n#&gt; married     0.0353\n#&gt; nodegr      0.1265\n#&gt; re74        0.0471\n#&gt; I(re74^2)   0.0471\n#&gt; re75        0.1075\n#&gt; I(re75^2)   0.1075\n#&gt; u74         0.0419\n#&gt; u75         0.0846\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance         0.4468        0.4284          0.1571     1.3077    0.0387\n#&gt; age             25.8162       25.1351          0.0952     1.1734    0.0243\n#&gt; I(age^2)       717.3946      675.1676          0.0979     1.1512    0.0243\n#&gt; educ            10.3459       10.2649          0.0403     1.2869    0.0174\n#&gt; I(educ^2)      111.0595      108.4919          0.0653     1.3938    0.0174\n#&gt; black            0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp             0.0595        0.0703         -0.0457          .    0.0108\n#&gt; married          0.1892        0.1892          0.0000          .    0.0000\n#&gt; nodegr           0.7081        0.7676         -0.1308          .    0.0595\n#&gt; re74          2095.5740     1741.2109          0.0725     1.5797    0.0146\n#&gt; I(re74^2) 28141433.9907 18066538.6428          0.0883     3.5436    0.0146\n#&gt; re75          1532.0556     1314.8073          0.0675     1.3933    0.0264\n#&gt; I(re75^2) 12654752.6909  9126579.7979          0.0630     3.4873    0.0264\n#&gt; u74              0.7081        0.7243         -0.0357          .    0.0162\n#&gt; u75              0.6000        0.6108         -0.0221          .    0.0108\n#&gt;           eCDF Max Std. Pair Dist.\n#&gt; distance    0.1189          0.1585\n#&gt; age         0.0541          0.8159\n#&gt; I(age^2)    0.0541          0.7701\n#&gt; educ        0.0595          0.7662\n#&gt; I(educ^2)   0.0595          0.7604\n#&gt; black       0.0054          0.5798\n#&gt; hisp        0.0108          0.2286\n#&gt; married     0.0000          0.2378\n#&gt; nodegr      0.0595          0.5588\n#&gt; re74        0.0432          0.6080\n#&gt; I(re74^2)   0.0432          0.3620\n#&gt; re75        0.0649          0.7292\n#&gt; I(re75^2)   0.0649          0.3690\n#&gt; u74         0.0162          0.7728\n#&gt; u75         0.0108          0.7282\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\nShow the code# Same as above but calculate average treatment effect\nrr.ate &lt;- Match(Y = lalonde$re78, \n                Tr = lalonde$treat, \n                X = lalonde$lr_ps,\n                M = 1,\n                ties = FALSE, \n                replace = FALSE, \n                estimand='ATE')\nsummary(rr.ate) # Here the estimate is ATE\n#&gt; \n#&gt; Estimate...  2036.6 \n#&gt; SE.........  501.71 \n#&gt; T-stat.....  4.0592 \n#&gt; p.val......  4.9233e-05 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  370 \n#&gt; Matched number of observations  (unweighted).  370\n\n\n\nShow the code## Genetic Matching\nrr.gen &lt;- GenMatch(Tr = lalonde$treat, \n                   X = lalonde$lr_ps, \n                   BalanceMatrix = lalonde[,all.vars(lalonde_formu)[-1]],\n                   estimand = 'ATE', \n                   M = 1, \n                   pop.size = 16,\n                   print.level = 0)\nrr.gen.mout &lt;- Match(Y = lalonde$re78, \n                     Tr = lalonde$treat, \n                     X = lalonde$lr_ps,\n                     estimand = 'ATE',\n                     Weight.matrix = rr.gen)\nsummary(rr.gen.mout)\n#&gt; \n#&gt; Estimate...  2086.5 \n#&gt; AI SE......  815.65 \n#&gt; T-stat.....  2.5581 \n#&gt; p.val......  0.010524 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  445 \n#&gt; Matched number of observations  (unweighted).  671\n\n\n\nShow the code## Partial exact matching\nrr2 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = factor(lalonde$nodegr),\n               print.level = 0)\nsummary(rr2)\n#&gt; \n#&gt; Estimate...  2014.4 \n#&gt; SE.........  702.05 \n#&gt; T-stat.....  2.8693 \n#&gt; p.val......  0.0041132 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\nShow the code## Partial exact matching on two covariates\nrr3 &lt;- Matchby(Y = lalonde$re78, \n               Tr = lalonde$treat, \n               X = lalonde$lr_ps, \n               by = lalonde[,c('nodegr','married')],\n               print.level = 0)\nsummary(rr3)\n#&gt; \n#&gt; Estimate...  1894 \n#&gt; SE.........  705.3 \n#&gt; T-stat.....  2.6853 \n#&gt; p.val......  0.0072455 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  },
  {
    "objectID": "matching.html#示例",
    "href": "matching.html#示例",
    "title": "\n3  匹配（Matching）\n",
    "section": "\n3.4 示例",
    "text": "3.4 示例\n\n\n变量名\n描述\n\n\n\nage\n年龄\n\n\neduc\n受教育年限\n\n\nblack\n分类变量，1为黑人\n\n\nhisp\n分类变量，1为西班牙裔\n\n\nmarried\n分类变量，1为已婚\n\n\nnodegr\n分类变量，1为有高中学历证书\n\n\nre74\n1974年的收入\n\n\nre75\n1975年的收入\n\n\nre78\n1978年的收入\n\n\nu74\n分类变量，1为1974年收入为零\n\n\nu75\n分类变量，1为1975年收入为零\n\n\ntreat\n分类变量，1为实验组\n\n\n\n\n3.4.1 估计倾向值分数\n\nShow the codeattach(lalonde)\nglm_ps &lt;- glm(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    family = binomial(link = 'logit')\n)\n\npsm1 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = TRUE)\nsummary(psm1)\n#&gt; \n#&gt; Estimate...  2624.3 \n#&gt; AI SE......  802.19 \n#&gt; T-stat.....  3.2714 \n#&gt; p.val......  0.0010702 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  344\n\n\n如上所示，使用1对1样本可替代匹配法，实验组平均效应为2624.3，因果效应的标准误为803.19，t值为3.2714，p值为0.0010702&lt;0.05，表明估计的实验组平均处理效应有统计学差异。\n\nShow the codepsm2 &lt;- Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             M=1,\n             replace = FALSE)\nsummary(psm2)\n#&gt; \n#&gt; Estimate...  1996.3 \n#&gt; SE.........  643.88 \n#&gt; T-stat.....  3.1005 \n#&gt; p.val......  0.0019319 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  185\n\n\n\n3.4.2 检验平衡\n受试者个体同质性，是否随机分配\n协变量分布是否平衡，是否重合：\n以age 为例，实验组匹配前25.816匹配后25.816，对照组匹配前25.054匹配后25.692 ，匹配后实验组与对照组更接近了；T-test p-value &gt; 0.05 ，表示匹配前后age 均值无统计学差异；KS Bootstrap p-value &gt; 0.05 ，表示匹配前后age 分布无统计学差异\n***** (V1) age *****                Before Matching          After Matching \n\nmean   treatment........          25.816             25.816  \nmean control..........     25.054            25.692 \nstd mean diff.........     10.655            1.7342 \n\nmean raw eQQ diff.....    0.94054           0.73837  \nmed  raw eQQ diff.....          1                 0  \nmax  raw eQQ diff.....          7                 9   \n\nmean eCDF diff........   0.025364          0.021893  \nmed  eCDF diff........   0.022193          0.020349  \nmax  eCDF diff........   0.065177          0.061047   \n\nvar ratio (Tr/Co).....     1.0278             1.083  \nT-test p-value........    0.26594           0.84975  \nKS Bootstrap p-value..      0.526             0.355  \nKS Naive p-value......     0.7481           0.54314  \nKS Statistic..........   0.065177          0.061047 \n\nShow the codecheck_balance &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = psm1,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.692 \n#&gt; std mean diff.........     10.655             1.7342 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.73837 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.021893 \n#&gt; med  eCDF diff........   0.022193           0.020349 \n#&gt; max  eCDF diff........   0.065177           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278              1.083 \n#&gt; T-test p-value........    0.26594            0.84975 \n#&gt; KS Bootstrap p-value..      0.514              0.364 \n#&gt; KS Naive p-value......     0.7481            0.54314 \n#&gt; KS Statistic..........   0.065177           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.146 \n#&gt; std mean diff.........     12.806             9.9664 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.23256 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.016611 \n#&gt; med  eCDF diff........   0.012682           0.010174 \n#&gt; max  eCDF diff........    0.12651           0.061047 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2344 \n#&gt; T-test p-value........    0.15017             0.1842 \n#&gt; KS Bootstrap p-value..      0.003              0.183 \n#&gt; KS Naive p-value......   0.062873            0.54314 \n#&gt; KS Statistic..........    0.12651           0.061047 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692            0.86847 \n#&gt; std mean diff.........     4.4767            -6.9194 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.013081 \n#&gt; med  eCDF diff........  0.0081601           0.013081 \n#&gt; max  eCDF diff........    0.01632           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1572 \n#&gt; T-test p-value........    0.64736            0.40214 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769            0.04955 \n#&gt; std mean diff.........    -20.341             4.1792 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649           0.011628 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116           0.005814 \n#&gt; med  eCDF diff........   0.024116           0.005814 \n#&gt; max  eCDF diff........   0.048233           0.011628 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.1875 \n#&gt; T-test p-value........   0.064043            0.46063 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18423 \n#&gt; std mean diff.........     8.9995             1.2617 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.026163 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672           0.013081 \n#&gt; med  eCDF diff........   0.017672           0.013081 \n#&gt; max  eCDF diff........   0.035343           0.026163 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0207 \n#&gt; T-test p-value........    0.33425            0.89497 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.76757 \n#&gt; std mean diff.........    -27.751            -13.043 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.043605 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.021802 \n#&gt; med  eCDF diff........   0.063254           0.021802 \n#&gt; max  eCDF diff........    0.12651           0.043605 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1585 \n#&gt; T-test p-value........  0.0020368          0.0071385 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2193.3 \n#&gt; std mean diff.........   -0.23437            -2.0004 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             869.16 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.054701 \n#&gt; med  eCDF diff........     0.0158           0.050872 \n#&gt; max  eCDF diff........   0.047089            0.12209 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.75054 \n#&gt; T-test p-value........    0.98186            0.84996 \n#&gt; KS Bootstrap p-value..      0.575         &lt; 2.22e-16 \n#&gt; KS Naive p-value......    0.97023           0.011858 \n#&gt; KS Statistic..........   0.047089            0.12209 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2179.9 \n#&gt; std mean diff.........     8.2363            -20.125 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             590.34 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.050338 \n#&gt; med  eCDF diff........   0.061954           0.049419 \n#&gt; max  eCDF diff........    0.10748           0.098837 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.56563 \n#&gt; T-test p-value........    0.38527           0.079002 \n#&gt; KS Bootstrap p-value..      0.049               0.01 \n#&gt; KS Naive p-value......    0.16449           0.069435 \n#&gt; KS Statistic..........    0.10748           0.098837 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: &lt; 2.22e-16 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n\n\nShow the code# age 变平衡了\nqqplot(lalonde$age[psm1$index.control],lalonde$age[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nShow the code\n# re74 更不平衡了\nqqplot(lalonde$re74[psm1$index.control],lalonde$re74[psm1$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\nShow the code# # The covariates we want to match on\nx &lt;- cbind(age , educ , black , hisp , married , nodegr , re74  , re75)\n\n# The covariates we want to obtain balance on\nBalanceMatrix = x\nset.seed(100)\n\n\n\n# Genetic Matching 自动适配平衡\ngen_match &lt;- GenMatch(Tr=treat,\n                      X=glm_ps$fitted.values,\n                      BalanceMatrix = x,\n                      estimand = \"ATT\")\n#&gt; \n#&gt; \n#&gt; Sat Aug 31 15:02:33 2024\n#&gt; Domains:\n#&gt;  0.000000e+00   &lt;=  X1   &lt;=    1.000000e+03 \n#&gt; \n#&gt; Data Type: Floating Point\n#&gt; Operators (code number, name, population) \n#&gt;  (1) Cloning...........................  15\n#&gt;  (2) Uniform Mutation..................  12\n#&gt;  (3) Boundary Mutation.................  12\n#&gt;  (4) Non-Uniform Mutation..............  12\n#&gt;  (5) Polytope Crossover................  12\n#&gt;  (6) Simple Crossover..................  12\n#&gt;  (7) Whole Non-Uniform Mutation........  12\n#&gt;  (8) Heuristic Crossover...............  12\n#&gt;  (9) Local-Minimum Crossover...........  0\n#&gt; \n#&gt; SOFT Maximum Number of Generations: 100\n#&gt; Maximum Nonchanging Generations: 4\n#&gt; Population size       : 100\n#&gt; Convergence Tolerance: 1.000000e-03\n#&gt; \n#&gt; Not Using the BFGS Derivative Based Optimizer on the Best Individual Each Generation.\n#&gt; Not Checking Gradients before Stopping.\n#&gt; Using Out of Bounds Individuals.\n#&gt; \n#&gt; Maximization Problem.\n#&gt; GENERATION: 0 (initializing the population)\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 100, #Total UniqueCount: 100\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 4.810920e+02\n#&gt; variance........ 7.636997e+04\n#&gt; \n#&gt; GENERATION: 1\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 161\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 2.015230e+02\n#&gt; variance........ 6.039634e+04\n#&gt; \n#&gt; GENERATION: 2\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 217\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 9.873041e+01\n#&gt; variance........ 3.291501e+04\n#&gt; \n#&gt; GENERATION: 3\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 56, #Total UniqueCount: 273\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.042351e+02\n#&gt; variance........ 2.899583e+04\n#&gt; \n#&gt; GENERATION: 4\n#&gt; Lexical Fit..... 1.180299e-02  1.180299e-02  1.155612e-01  1.186261e-01  1.822343e-01  3.842491e-01  3.842491e-01  4.144313e-01  4.144313e-01  4.610718e-01  5.977650e-01  7.731052e-01  7.731052e-01  8.523060e-01  9.184104e-01  9.749549e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 331\n#&gt; var 1:\n#&gt; best............ 3.729259e+01\n#&gt; mean............ 1.050645e+02\n#&gt; variance........ 2.721152e+04\n#&gt; \n#&gt; GENERATION: 5\n#&gt; Lexical Fit..... 1.541148e-02  2.397991e-02  2.418950e-02  2.418950e-02  1.729273e-01  1.956942e-01  3.942807e-01  3.942807e-01  6.059370e-01  6.059370e-01  6.074259e-01  6.137460e-01  8.414918e-01  8.538318e-01  9.621995e-01  9.621995e-01  \n#&gt; #unique......... 58, #Total UniqueCount: 389\n#&gt; var 1:\n#&gt; best............ 2.941808e-01\n#&gt; mean............ 8.418536e+01\n#&gt; variance........ 1.578216e+04\n#&gt; \n#&gt; GENERATION: 6\n#&gt; Lexical Fit..... 4.145421e-02  4.145421e-02  4.499068e-02  4.499068e-02  1.608408e-01  1.806532e-01  2.764640e-01  4.729068e-01  4.729068e-01  6.940013e-01  6.940013e-01  7.762162e-01  8.635587e-01  8.667712e-01  8.667712e-01  9.507460e-01  \n#&gt; #unique......... 62, #Total UniqueCount: 451\n#&gt; var 1:\n#&gt; best............ 7.310932e-02\n#&gt; mean............ 9.403781e+01\n#&gt; variance........ 2.447312e+04\n#&gt; \n#&gt; GENERATION: 7\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.419097e-02  6.248288e-02  1.198352e-01  2.880778e-01  3.513309e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.836843e-01  8.920699e-01  8.920699e-01  \n#&gt; #unique......... 61, #Total UniqueCount: 512\n#&gt; var 1:\n#&gt; best............ 8.760968e-02\n#&gt; mean............ 1.016562e+02\n#&gt; variance........ 4.437002e+04\n#&gt; \n#&gt; GENERATION: 8\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 60, #Total UniqueCount: 572\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 7.473970e+01\n#&gt; variance........ 2.676016e+04\n#&gt; \n#&gt; GENERATION: 9\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 55, #Total UniqueCount: 627\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 4.192386e+01\n#&gt; variance........ 1.737331e+04\n#&gt; \n#&gt; GENERATION: 10\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 51, #Total UniqueCount: 678\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 6.242257e+01\n#&gt; variance........ 2.722981e+04\n#&gt; \n#&gt; GENERATION: 11\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 49, #Total UniqueCount: 727\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.280735e+01\n#&gt; variance........ 1.784927e+04\n#&gt; \n#&gt; GENERATION: 12\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 50, #Total UniqueCount: 777\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 5.682777e+01\n#&gt; variance........ 2.131922e+04\n#&gt; \n#&gt; GENERATION: 13\n#&gt; Lexical Fit..... 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; #unique......... 53, #Total UniqueCount: 830\n#&gt; var 1:\n#&gt; best............ 8.627748e-02\n#&gt; mean............ 3.877940e+01\n#&gt; variance........ 1.599211e+04\n#&gt; \n#&gt; 'wait.generations' limit reached.\n#&gt; No significant improvement in 4 generations.\n#&gt; \n#&gt; Solution Lexical Fitness Value:\n#&gt; 4.177047e-02  4.177047e-02  4.559074e-02  6.427954e-02  1.215371e-01  2.846955e-01  3.519026e-01  4.150287e-01  4.150287e-01  8.316757e-01  8.316757e-01  8.667712e-01  8.667712e-01  8.794500e-01  8.948772e-01  8.948772e-01  \n#&gt; \n#&gt; Parameters at the Solution:\n#&gt; \n#&gt;  X[ 1] : 8.627748e-02\n#&gt; \n#&gt; Solution Found Generation 8\n#&gt; Number of Generations Run 13\n#&gt; \n#&gt; Sat Aug 31 15:02:38 2024\n#&gt; Total run time : 0 hours 0 minutes and 5 seconds\n\nPSM &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\n\ncheck_balance2 &lt;- MatchBalance(\n    formul = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    match.out = PSM,\n    nboots = 1000,data = lalonde\n)\n#&gt; \n#&gt; ***** (V1) age *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     25.816             25.816 \n#&gt; mean control..........     25.054             25.217 \n#&gt; std mean diff.........     10.655             8.3769 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.94054            0.46217 \n#&gt; med  raw eQQ diff.....          1                  0 \n#&gt; max  raw eQQ diff.....          7                  9 \n#&gt; \n#&gt; mean eCDF diff........   0.025364           0.012952 \n#&gt; med  eCDF diff........   0.022193           0.010225 \n#&gt; max  eCDF diff........   0.065177            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0278             1.2224 \n#&gt; T-test p-value........    0.26594             0.3519 \n#&gt; KS Bootstrap p-value..      0.503              0.734 \n#&gt; KS Naive p-value......     0.7481            0.89488 \n#&gt; KS Statistic..........   0.065177            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V2) educ *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     10.346             10.346 \n#&gt; mean control..........     10.088             10.188 \n#&gt; std mean diff.........     12.806             7.8605 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.40541            0.17587 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          2                  2 \n#&gt; \n#&gt; mean eCDF diff........   0.028698           0.012562 \n#&gt; med  eCDF diff........   0.012682           0.010225 \n#&gt; max  eCDF diff........    0.12651            0.03681 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.5513             1.2791 \n#&gt; T-test p-value........    0.15017             0.2847 \n#&gt; KS Bootstrap p-value..      0.011              0.456 \n#&gt; KS Naive p-value......   0.062873            0.89488 \n#&gt; KS Statistic..........    0.12651            0.03681 \n#&gt; \n#&gt; \n#&gt; ***** (V3) black *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.84324            0.84324 \n#&gt; mean control..........    0.82692              0.868 \n#&gt; std mean diff.........     4.4767            -6.7917 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.016216           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........  0.0081601           0.017382 \n#&gt; med  eCDF diff........  0.0081601           0.017382 \n#&gt; max  eCDF diff........    0.01632           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.92503             1.1537 \n#&gt; T-test p-value........    0.64736            0.41503 \n#&gt; \n#&gt; \n#&gt; ***** (V4) hisp *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........   0.059459           0.059459 \n#&gt; mean control..........    0.10769           0.057132 \n#&gt; std mean diff.........    -20.341            0.98148 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.048649            0.00818 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.024116            0.00409 \n#&gt; med  eCDF diff........   0.024116            0.00409 \n#&gt; max  eCDF diff........   0.048233            0.00818 \n#&gt; \n#&gt; var ratio (Tr/Co).....    0.58288             1.0382 \n#&gt; T-test p-value........   0.064043            0.86677 \n#&gt; \n#&gt; \n#&gt; ***** (V5) married *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.18919            0.18919 \n#&gt; mean control..........    0.15385            0.18101 \n#&gt; std mean diff.........     8.9995             2.0837 \n#&gt; \n#&gt; mean raw eQQ diff.....   0.037838           0.018405 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.017672          0.0092025 \n#&gt; med  eCDF diff........   0.017672          0.0092025 \n#&gt; max  eCDF diff........   0.035343           0.018405 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.1802             1.0348 \n#&gt; T-test p-value........    0.33425            0.83168 \n#&gt; \n#&gt; \n#&gt; ***** (V6) nodegr *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........    0.70811            0.70811 \n#&gt; mean control..........    0.83462            0.75333 \n#&gt; std mean diff.........    -27.751            -9.9207 \n#&gt; \n#&gt; mean raw eQQ diff.....    0.12432           0.034765 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....          1                  1 \n#&gt; \n#&gt; mean eCDF diff........   0.063254           0.017382 \n#&gt; med  eCDF diff........   0.063254           0.017382 \n#&gt; max  eCDF diff........    0.12651           0.034765 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.4998             1.1123 \n#&gt; T-test p-value........  0.0020368            0.04177 \n#&gt; \n#&gt; \n#&gt; ***** (V7) re74 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     2095.6             2095.6 \n#&gt; mean control..........       2107             2018.1 \n#&gt; std mean diff.........   -0.23437             1.5857 \n#&gt; \n#&gt; mean raw eQQ diff.....     487.98             648.91 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....       8413              10305 \n#&gt; \n#&gt; mean eCDF diff........   0.019223           0.037077 \n#&gt; med  eCDF diff........     0.0158           0.033742 \n#&gt; max  eCDF diff........   0.047089           0.087935 \n#&gt; \n#&gt; var ratio (Tr/Co).....     0.7381            0.86668 \n#&gt; T-test p-value........    0.98186            0.87945 \n#&gt; KS Bootstrap p-value..      0.555              0.002 \n#&gt; KS Naive p-value......    0.97023           0.045591 \n#&gt; KS Statistic..........   0.047089           0.087935 \n#&gt; \n#&gt; \n#&gt; ***** (V8) re75 *****\n#&gt;                        Before Matching        After Matching\n#&gt; mean treatment........     1532.1             1532.1 \n#&gt; mean control..........     1266.9             2079.5 \n#&gt; std mean diff.........     8.2363            -17.005 \n#&gt; \n#&gt; mean raw eQQ diff.....     367.61             532.46 \n#&gt; med  raw eQQ diff.....          0                  0 \n#&gt; max  raw eQQ diff.....     2110.2             8092.9 \n#&gt; \n#&gt; mean eCDF diff........   0.050834           0.040137 \n#&gt; med  eCDF diff........   0.061954             0.0409 \n#&gt; max  eCDF diff........    0.10748           0.083845 \n#&gt; \n#&gt; var ratio (Tr/Co).....     1.0763            0.64518 \n#&gt; T-test p-value........    0.38527            0.12154 \n#&gt; KS Bootstrap p-value..      0.038               0.02 \n#&gt; KS Naive p-value......    0.16449            0.06428 \n#&gt; KS Statistic..........    0.10748           0.083845 \n#&gt; \n#&gt; \n#&gt; Before Matching Minimum p.value: 0.0020368 \n#&gt; Variable Name(s): nodegr  Number(s): 6 \n#&gt; \n#&gt; After Matching Minimum p.value: 0.002 \n#&gt; Variable Name(s): re74  Number(s): 7\n\n# age 变平衡了\nqqplot(lalonde$age[PSM$index.control],lalonde$age[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\nShow the code\n# re74 也变平衡了\nqqplot(lalonde$re74[PSM$index.control],lalonde$re74[PSM$index.treated])\nabline(a=0,b=1)\n\n\n\n\n\n\n\n\n3.4.3 敏感性分析\n\nShow the codelibrary(rbounds)\npsens(x =lalonde[PSM$index.treated,\"re78\"],\n      y =lalonde[PSM$index.control,\"re78\"] ,\n      Gamma = 2,\n      GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  1e-04 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0       1e-04      0.0001\n#&gt;    1.1       0e+00      0.0015\n#&gt;    1.2       0e+00      0.0142\n#&gt;    1.3       0e+00      0.0693\n#&gt;    1.4       0e+00      0.2048\n#&gt;    1.5       0e+00      0.4152\n#&gt;    1.6       0e+00      0.6393\n#&gt;    1.7       0e+00      0.8140\n#&gt;    1.8       0e+00      0.9191\n#&gt;    1.9       0e+00      0.9699\n#&gt;    2.0       0e+00      0.9903\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n# psens\n\n\n对PSM（Y=re78）使用psens()进行Wilcoxon 符合秩检验，当τ=1.3，p值就大于0.05了，说明处理发生比为1.3时，就可以改变原先对于处理效应的结论，也就是说，这个隐藏性偏差不必太大就可以改变原来的结论，因此分析结果对隐藏性排除的影响非常敏感，结论不可靠。\n对 PSM（Y=re78）使用Hodges-Lehmann点估计检验法 hlsens() ，当τ=1.5，其95%置信区间包含零，说明此时处理效应是无效的。说明处理发生比为1.5时，隐藏性偏差就可以改变原来的结论，因此匹配后的结论不可靠。\n\nShow the codex = lalonde[PSM$index.treated, \"re78\"]\ny = lalonde[PSM$index.control, \"re78\"]\nhlsens(x, y,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1527.95 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0 1527.900000      1527.9\n#&gt;    1.1  917.250000      1580.2\n#&gt;    1.2  608.050000      1918.7\n#&gt;    1.3  338.450000      2141.0\n#&gt;    1.4  114.850000      2407.3\n#&gt;    1.5   -0.050046      2631.4\n#&gt;    1.6 -154.050000      2850.3\n#&gt;    1.7 -378.150000      3072.7\n#&gt;    1.8 -545.350000      3258.1\n#&gt;    1.9 -706.350000      3474.2\n#&gt;    2.0 -867.650000      3678.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\n\n共同支持域的查验\n\nShow the codesum(glm_ps$fitted.values[lalonde$treat==1]&gt; \n        max(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 4\n\nsum(glm_ps$fitted.values[lalonde$treat==1]&lt; \n        min(glm_ps$fitted.values[lalonde$treat==0]))\n#&gt; [1] 0\n\n\n丢弃的实验组样本共有4个。185-181\n\nShow the codeattach(lalonde)\nsummary(PSM)\n#&gt; \n#&gt; Estimate...  2439.3 \n#&gt; AI SE......  813.4 \n#&gt; T-stat.....  2.9989 \n#&gt; p.val......  0.0027099 \n#&gt; \n#&gt; Original number of observations..............  445 \n#&gt; Original number of treated obs...............  185 \n#&gt; Matched number of observations...............  185 \n#&gt; Matched number of observations  (unweighted).  489\nPSM_CS &lt;-  Match(Y=re78,\n             Tr = treat,\n             X=glm_ps$fitted.values,\n             estimand = \"ATT\",\n             Weight.matrix = gen_match,\n             replace = TRUE,\n             CommonSupport = TRUE)\nsummary(PSM_CS)\n#&gt; \n#&gt; Estimate...  2330 \n#&gt; AI SE......  821.6 \n#&gt; T-stat.....  2.836 \n#&gt; p.val......  0.0045684 \n#&gt; \n#&gt; Original number of observations..............  430 \n#&gt; Original number of treated obs...............  181 \n#&gt; Matched number of observations...............  181 \n#&gt; Matched number of observations  (unweighted).  468\ndetach(lalonde)\n\n\n有查验共同支持域的ATT（2330），与无查验共同支持域（2439.3）存在差异，因此必须重新改进倾向值分析。\n\n3.4.4 MatchIt\n\n3.4.4.1 匹配数据\n\nShow the codelibrary(MatchIt)\nNM &lt;- MatchIt::matchit(\n    formula = treat ~ age + educ + black + hisp + married + nodegr + re74  + re75,\n    data = lalonde,\n    method = \"nearest\", # 最近邻匹配\n    ratio = 1, # 1:1\n    replace = FALSE\n)\nsummary(NM)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n\n3.4.4.2 评估质量\n\nShow the code# 散点图展示了匹配后实验组和对照组样本倾向值的分布，凸显了分布平衡与不平衡，分布缺乏重合\nplot(NM,type = \"jitter\")\n\n\n\n\n\n\n#&gt; To identify the units, use first mouse button; to stop, use second.\n\n\nShow the code# QQ图 展示了 匹配前（All）匹配后（Matched）的平衡情况\nplot(NM,type = \"QQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# 直方图展示了匹配前后倾向值的分布\nplot(NM,type = \"hist\")\n\n\n\n\n\n\n\n\nShow the code# 标准化平衡统计值，Std. Mean Diff.\nsummary(NM,standardize = TRUE)\n#&gt; \n#&gt; Call:\n#&gt; MatchIt::matchit(formula = treat ~ age + educ + black + hisp + \n#&gt;     married + nodegr + re74 + re75, data = lalonde, method = \"nearest\", \n#&gt;     replace = FALSE, ratio = 1)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4001          0.3935     1.0471    0.1117\n#&gt; age            25.8162       25.0538          0.1066     1.0278    0.0254\n#&gt; educ           10.3459       10.0885          0.1281     1.5513    0.0287\n#&gt; black           0.8432        0.8269          0.0449          .    0.0163\n#&gt; hisp            0.0595        0.1077         -0.2040          .    0.0482\n#&gt; married         0.1892        0.1538          0.0902          .    0.0353\n#&gt; nodegr          0.7081        0.8346         -0.2783          .    0.1265\n#&gt; re74         2095.5740     2107.0268         -0.0023     0.7381    0.0192\n#&gt; re75         1532.0556     1266.9092          0.0824     1.0763    0.0508\n#&gt;          eCDF Max\n#&gt; distance   0.2140\n#&gt; age        0.0652\n#&gt; educ       0.1265\n#&gt; black      0.0163\n#&gt; hisp       0.0482\n#&gt; married    0.0353\n#&gt; nodegr     0.1265\n#&gt; re74       0.0471\n#&gt; re75       0.1075\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4377        0.4267          0.1152     1.0987    0.0298\n#&gt; age            25.8162       25.8757         -0.0083     0.9551    0.0121\n#&gt; educ           10.3459       10.1459          0.0995     1.3748    0.0220\n#&gt; black           0.8432        0.8486         -0.0149          .    0.0054\n#&gt; hisp            0.0595        0.0649         -0.0229          .    0.0054\n#&gt; married         0.1892        0.2000         -0.0276          .    0.0108\n#&gt; nodegr          0.7081        0.7730         -0.1427          .    0.0649\n#&gt; re74         2095.5740     1659.5326          0.0892     1.1752    0.0351\n#&gt; re75         1532.0556     1359.6980          0.0535     0.9270    0.0502\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.1027          0.1302\n#&gt; age        0.0432          0.8711\n#&gt; educ       0.0757          0.6533\n#&gt; black      0.0054          0.4906\n#&gt; hisp       0.0054          0.2057\n#&gt; married    0.0108          0.7177\n#&gt; nodegr     0.0649          0.2378\n#&gt; re74       0.0865          0.6297\n#&gt; re75       0.1081          0.7019\n#&gt; \n#&gt; Sample Sizes:\n#&gt;           Control Treated\n#&gt; All           260     185\n#&gt; Matched       185     185\n#&gt; Unmatched      75       0\n#&gt; Discarded       0       0\n\n\n继续改进，调整模型和协变量\n\n3.4.4.3 计算平均处理效应\n为了简化步骤，以当前的结果进行匹配后分析。\n\nShow the code\n# 提取匹配后的样本\nmData &lt;- match.data(NM,group = \"all\")\nmData_trt &lt;- match.data(NM,group = \"treat\")\nmData_ctrl &lt;- match.data(NM,group = \"control\")\n \n# 包从CRAN剔除了\n\n\n\nShow the codelibrary(rbounds)\npsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value \n#&gt;  \n#&gt; Unconfounded estimate ....  0.0199 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0      0.0199      0.0199\n#&gt;    1.1      0.0048      0.0639\n#&gt;    1.2      0.0010      0.1491\n#&gt;    1.3      0.0002      0.2749\n#&gt;    1.4      0.0000      0.4248\n#&gt;    1.5      0.0000      0.5755\n#&gt;    1.6      0.0000      0.7076\n#&gt;    1.7      0.0000      0.8108\n#&gt;    1.8      0.0000      0.8844\n#&gt;    1.9      0.0000      0.9328\n#&gt;    2.0      0.0000      0.9627\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt; \n\nhlsens(x =mData_trt$re78,\n      y =mData_ctrl$re78 ,Gamma = 2,GammaInc = 0.1)\n#&gt; \n#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate \n#&gt;  \n#&gt; Unconfounded estimate ....  1435.08 \n#&gt; \n#&gt;  Gamma Lower bound Upper bound\n#&gt;    1.0  1.4351e+03      1435.1\n#&gt;    1.1  8.0828e+02      1515.9\n#&gt;    1.2  4.6298e+02      1809.0\n#&gt;    1.3  1.8238e+02      2178.1\n#&gt;    1.4 -2.0266e-02      2439.4\n#&gt;    1.5 -2.4892e+02      2678.5\n#&gt;    1.6 -4.5162e+02      2937.5\n#&gt;    1.7 -6.7212e+02      3184.0\n#&gt;    1.8 -8.9732e+02      3462.6\n#&gt;    1.9 -1.1328e+03      3651.1\n#&gt;    2.0 -1.3022e+03      3848.9\n#&gt; \n#&gt;  Note: Gamma is Odds of Differential Assignment To\n#&gt;  Treatment Due to Unobserved Factors \n#&gt;",
    "crumbs": [
      "倾向性评分",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>匹配（Matching）</span>"
    ]
  }
]